"""
LangGraph Orchestrator-Worker æ¨¡å¼ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphå®ç°åè°ƒè€…-å·¥ä½œè€…æ¨¡å¼ï¼š
- åè°ƒè€…(orchestrator): è´Ÿè´£è§„åˆ’å’Œåˆ†é…ä»»åŠ¡
- å·¥ä½œè€…(worker): æ‰§è¡Œå…·ä½“çš„ä»»åŠ¡
- åˆæˆå™¨(synthesizer): æ•´åˆæ‰€æœ‰å·¥ä½œè€…çš„ç»“æœ

ä¸»è¦ç‰¹ç‚¹ï¼š
1. ä½¿ç”¨Send APIè¿›è¡ŒåŠ¨æ€ä»»åŠ¡åˆ†é…
2. å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥ä½œè€…ä»»åŠ¡
3. çŠ¶æ€ç®¡ç†å’Œç»“æœèšåˆ
"""

import operator
from typing import Annotated, TypedDict, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.pydantic_v1 import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
import os

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

# è·å–æ—¥å¿—å™¨
logger = config.logger

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# åˆå§‹åŒ–LLMæ¨¡å‹
# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model=MODEL_NAME,
    temperature=0.1,  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿è¾“å‡ºçš„ä¸€è‡´æ€§
    max_tokens=1000   # é™åˆ¶è¾“å‡ºé•¿åº¦
)

# å®šä¹‰æŠ¥å‘Šç« èŠ‚çš„ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
class Section(BaseModel):
    name: str = Field(description="ç« èŠ‚åç§°")
    description: str = Field(description="ç« èŠ‚å†…å®¹æè¿°")

class Sections(BaseModel):
    sections: List[Section] = Field(description="æŠ¥å‘Šçš„æ‰€æœ‰ç« èŠ‚")

# ä¸ºLLMæ·»åŠ ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›
planner = llm.with_structured_output(Sections)

# å®šä¹‰å›¾çŠ¶æ€
class State(TypedDict):
    topic: str  # æŠ¥å‘Šä¸»é¢˜
    sections: List[Section]  # æŠ¥å‘Šç« èŠ‚åˆ—è¡¨
    completed_sections: Annotated[List[str], operator.add]  # æ‰€æœ‰å·¥ä½œè€…å¹¶è¡Œå†™å…¥æ­¤é”®
    final_report: str  # æœ€ç»ˆæŠ¥å‘Š

# å®šä¹‰å·¥ä½œè€…çŠ¶æ€
class WorkerState(TypedDict):
    section: Section
    completed_sections: Annotated[List[str], operator.add]

def orchestrator(state: State):
    """åè°ƒè€…ï¼šç”ŸæˆæŠ¥å‘Šè®¡åˆ’"""
    print(f"ğŸ¯ åè°ƒè€…æ­£åœ¨ä¸ºä¸»é¢˜ '{state['topic']}' åˆ¶å®šè®¡åˆ’...")
    
    # ç”ŸæˆæŠ¥å‘Šç« èŠ‚è®¡åˆ’
    report_sections = planner.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ¥å‘Šè§„åˆ’ä¸“å®¶ã€‚è¯·ä¸ºç»™å®šçš„ä¸»é¢˜ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æŠ¥å‘Šå¤§çº²ï¼ŒåŒ…å«3-5ä¸ªç« èŠ‚ã€‚æ¯ä¸ªç« èŠ‚éƒ½åº”è¯¥æœ‰æ˜ç¡®çš„åç§°å’Œæè¿°ã€‚"),
        HumanMessage(content=f"è¯·ä¸ºä¸»é¢˜ '{state['topic']}' åˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„æŠ¥å‘Šå¤§çº²ã€‚")
    ])
    
    print(f"ğŸ“‹ å·²ç”Ÿæˆ {len(report_sections.sections)} ä¸ªç« èŠ‚çš„è®¡åˆ’")
    return {"sections": report_sections.sections}

def llm_call(state: WorkerState):
    """å·¥ä½œè€…ï¼šæ’°å†™æŠ¥å‘Šç« èŠ‚"""
    section = state['section']
    print(f"ğŸ“ å·¥ä½œè€…æ­£åœ¨æ’°å†™ç« èŠ‚: {section.name}")
    
    # ç”Ÿæˆç« èŠ‚å†…å®¹
    section_content = llm.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„ç« èŠ‚åç§°å’Œæè¿°æ’°å†™è¯¦ç»†çš„å†…å®¹ã€‚ä½¿ç”¨markdownæ ¼å¼ï¼Œå†…å®¹è¦ä¸“ä¸šã€è¯¦ç»†ä¸”æœ‰æ¡ç†ã€‚"),
        HumanMessage(content=f"è¯·æ’°å†™ç« èŠ‚ '{section.name}' çš„å†…å®¹ã€‚\nç« èŠ‚æè¿°: {section.description}\n\nè¯·æä¾›è¯¦ç»†ã€ä¸“ä¸šçš„å†…å®¹ã€‚")
    ])
    
    print(f"âœ… ç« èŠ‚ '{section.name}' æ’°å†™å®Œæˆ")
    return {"completed_sections": [section_content.content]}

def synthesizer(state: State):
    """åˆæˆå™¨ï¼šæ•´åˆå®Œæ•´æŠ¥å‘Š"""
    print("ğŸ”— åˆæˆå™¨æ­£åœ¨æ•´åˆæ‰€æœ‰ç« èŠ‚...")
    
    # è·å–æ‰€æœ‰å®Œæˆçš„ç« èŠ‚
    completed_sections = state["completed_sections"]
    
    # æ ¼å¼åŒ–ç« èŠ‚å†…å®¹
    completed_report_sections = "\n\n---\n\n".join(completed_sections)
    
    # æ·»åŠ æŠ¥å‘Šæ ‡é¢˜å’Œæ€»ç»“
    final_report = f"# {state['topic']}\n\n{completed_report_sections}\n\n---\n\n## æŠ¥å‘Šæ€»ç»“\n\næœ¬æŠ¥å‘Šæ¶µç›–äº†å…³äº {state['topic']} çš„å…¨é¢åˆ†æï¼ŒåŒ…å« {len(completed_sections)} ä¸ªä¸»è¦ç« èŠ‚ã€‚"
    
    print("ğŸ‰ æŠ¥å‘Šæ•´åˆå®Œæˆï¼")
    return {"final_report": final_report}

def assign_workers(state: State):
    """åˆ†é…å·¥ä½œè€…ï¼šä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºå¹¶è¡Œå·¥ä½œè€…"""
    print(f"ğŸš€ æ­£åœ¨ä¸º {len(state['sections'])} ä¸ªç« èŠ‚åˆ†é…å·¥ä½œè€…...")
    
    # ä½¿ç”¨Send APIä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºå¹¶è¡Œå·¥ä½œè€…
    # todo workstats ä¸stats è½¬æ¢
    return [Send("llm_call", {"section": s}) for s in state["sections"]]

def should_continue(state: State):
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œ"""
    # å¦‚æœæ‰€æœ‰ç« èŠ‚éƒ½å®Œæˆäº†ï¼Œç»§ç»­åˆ°åˆæˆå™¨
    if len(state.get("completed_sections", [])) == len(state.get("sections", [])):
        return "synthesizer"
    return "llm_call"

# æ„å»ºå·¥ä½œæµ
def build_orchestrator_worker_graph():
    """æ„å»ºåè°ƒè€…-å·¥ä½œè€…å›¾"""
    print("ğŸ—ï¸ æ­£åœ¨æ„å»ºåè°ƒè€…-å·¥ä½œè€…å›¾...")
    
    # åˆ›å»ºçŠ¶æ€å›¾
    orchestrator_worker_builder = StateGraph(State)
    
    # æ·»åŠ èŠ‚ç‚¹
    orchestrator_worker_builder.add_node("orchestrator", orchestrator)
    orchestrator_worker_builder.add_node("llm_call", llm_call)
    orchestrator_worker_builder.add_node("synthesizer", synthesizer)
    
    # æ·»åŠ è¾¹è¿æ¥èŠ‚ç‚¹
    orchestrator_worker_builder.add_edge(START, "orchestrator")
    orchestrator_worker_builder.add_conditional_edges(
        "orchestrator", 
        assign_workers, 
        ["llm_call"]
    )
    orchestrator_worker_builder.add_edge("llm_call", "synthesizer")
    orchestrator_worker_builder.add_edge("synthesizer", END)
    
    # ç¼–è¯‘å›¾
    graph = orchestrator_worker_builder.compile()
    print("âœ… å›¾æ„å»ºå®Œæˆï¼")
    
    return graph


def run_simple_example():
    """è¿è¡Œç®€åŒ–ç¤ºä¾‹ï¼ˆä¸ä½¿ç”¨æµå¼è¾“å‡ºï¼‰"""
    print("=" * 60)
    print("ğŸš€ LangGraph åè°ƒè€…-å·¥ä½œè€…æ¨¡å¼ç®€åŒ–ç¤ºä¾‹")
    print("=" * 60)
    
    # æ„å»ºå›¾
    graph = build_orchestrator_worker_graph()
    
    # å®šä¹‰æŠ¥å‘Šä¸»é¢˜
    topic = "å¯æŒç»­å‘å±•ä¸ç¯å¢ƒä¿æŠ¤"
    
    print(f"\nğŸ“‹ å¼€å§‹ç”Ÿæˆå…³äº '{topic}' çš„æŠ¥å‘Š...")
    
    # æ‰§è¡Œå›¾
    try:
        final_state = graph.invoke({"topic": topic})
        
        print("\n" + "=" * 60)
        print("ğŸ“„ æœ€ç»ˆæŠ¥å‘Š")
        print("=" * 60)
        print(final_state["final_report"])
        
        return final_state
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return None

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    # æ³¨æ„ï¼šéœ€è¦è®¾ç½®æœ‰æ•ˆçš„OpenAI APIå¯†é’¥
    print("âš ï¸  è¯·ç¡®ä¿å·²è®¾ç½®æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
    print("   å¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ–ä¿®æ”¹ä»£ç ä¸­çš„APIå¯†é’¥")
    
    # è¿è¡Œç®€åŒ–ç¤ºä¾‹
    result = run_simple_example()
    
    if result:
        print("\nâœ… ç¤ºä¾‹æ‰§è¡ŒæˆåŠŸï¼")
    else:
        print("\nâŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
