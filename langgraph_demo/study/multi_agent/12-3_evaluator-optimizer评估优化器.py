"""
LangGraph ç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphå®ç°ç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨æ¨¡å¼ï¼š
- ç”Ÿæˆå™¨ï¼šè´Ÿè´£ç”Ÿæˆç¬‘è¯
- è¯„ä¼°å™¨ï¼šè¯„ä¼°ç¬‘è¯è´¨é‡å¹¶æä¾›åé¦ˆ
- ä¼˜åŒ–å™¨ï¼šæ ¹æ®åé¦ˆæ”¹è¿›ç¬‘è¯

ä¸»è¦ç‰¹ç‚¹ï¼š
- ä½¿ç”¨StateGraph APIæ„å»ºå·¥ä½œæµ
- ç»“æ„åŒ–è¯„ä¼°åé¦ˆ
- è¿­ä»£ä¼˜åŒ–ç›´åˆ°è¾¾åˆ°ç›®æ ‡è´¨é‡
"""

import os
import sys
from typing import TypedDict, Literal

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥é…ç½®
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

# å¯¼å…¥å¿…è¦çš„åº“
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model=config.model,
    temperature=0.1,
    max_tokens=1000
)



# å®šä¹‰çŠ¶æ€
class JokeState(TypedDict):
    topic: str
    joke: str
    feedback: str
    funny_or_not: str
    iteration_count: int

# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
class JokeFeedback(BaseModel):
    grade: Literal["funny", "not funny"] = Field(
        description="åˆ¤æ–­ç¬‘è¯æ˜¯å¦æœ‰è¶£"
    )
    feedback: str = Field(
        description="å¦‚æœç¬‘è¯ä¸å¤Ÿæœ‰è¶£ï¼Œæä¾›æ”¹è¿›å»ºè®®"
    )
    score: int = Field(
        description="ç¬‘è¯è´¨é‡è¯„åˆ† (1-10)",
        ge=1,
        le=10
    )

# todo ä¸ºLLMæ·»åŠ ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›
joke_evaluator = llm.with_structured_output(JokeFeedback)

def generate_joke(state: JokeState) -> JokeState:
    """ç”Ÿæˆç¬‘è¯"""
    topic = state["topic"]
    feedback = state.get("feedback", "")
    iteration = state.get("iteration_count", 0)
    
    print(f"ğŸ­ ç¬¬ {iteration + 1} æ¬¡å°è¯•ä¸ºè¯é¢˜ '{topic}' ç”Ÿæˆç¬‘è¯...")
    
    if feedback:
        prompt = f"è¯·ä¸ºè¯é¢˜ '{topic}' å†™ä¸€ä¸ªæœ‰è¶£çš„ç¬‘è¯ï¼Œå¹¶è€ƒè™‘ä»¥ä¸‹åé¦ˆï¼š{feedback}"
    else:
        prompt = f"è¯·ä¸ºè¯é¢˜ '{topic}' å†™ä¸€ä¸ªæœ‰è¶£çš„ç¬‘è¯ã€‚"
    
    response = llm.invoke(prompt)
    
    return {
        "joke": response.content,
        "iteration_count": iteration + 1
    }

def evaluate_joke(state: JokeState) -> JokeState:
    """è¯„ä¼°ç¬‘è¯"""
    joke = state["joke"]
    print(f"ğŸ” è¯„ä¼°ç¬‘è¯: {joke[:50]}...")
    
    feedback = joke_evaluator.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¬‘è¯è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹ç¬‘è¯çš„è´¨é‡ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚"),
        HumanMessage(content=f"è¯·è¯„ä¼°è¿™ä¸ªç¬‘è¯ï¼š\n\n{joke}")
    ])
    
    print(f"ğŸ“Š è¯„åˆ†: {feedback.score}/10, ç­‰çº§: {feedback.grade}")
    
    return {
        "funny_or_not": feedback.grade,
        "feedback": feedback.feedback
    }

def route_joke(state: JokeState) -> Literal["Accepted", "Rejected + Feedback"]:
    """æ ¹æ®è¯„ä¼°ç»“æœå†³å®šè·¯ç”±"""
    grade = state["funny_or_not"]
    score = state.get("score", 0)
    iteration = state.get("iteration_count", 0)
    
    print(f"ğŸ”„ è·¯ç”±å†³ç­–: ç­‰çº§={grade}, è¯„åˆ†={score}, è¿­ä»£={iteration}")
    
    # å¦‚æœç¬‘è¯æœ‰è¶£æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œåˆ™æ¥å—
    if grade == "funny" or iteration >= 5:
        return "Accepted"
    else:
        return "Rejected + Feedback"

def build_joke_evaluator_optimizer():
    """æ„å»ºç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨å›¾"""
    print("ğŸ—ï¸ æ„å»ºç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨å›¾...")
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(JokeState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("generate_joke", generate_joke)
    workflow.add_node("evaluate_joke", evaluate_joke)
    
    # æ·»åŠ è¾¹
    workflow.add_edge(START, "generate_joke")
    workflow.add_edge("generate_joke", "evaluate_joke")
    workflow.add_conditional_edges(
        "evaluate_joke",
        route_joke,
        {
            "Accepted": END,
            "Rejected + Feedback": "generate_joke"
        }
    )
    
    # ç¼–è¯‘å›¾
    chain = workflow.compile()
    print("âœ… ç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨å›¾æ„å»ºå®Œæˆï¼")
    
    return chain



# ===== 2. è¿è¡Œç¤ºä¾‹å‡½æ•° =====

def run_joke_evaluator_optimizer():
    """è¿è¡Œç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸš€ ç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨ç¤ºä¾‹")
    print("=" * 60)
    
    # æ„å»ºå›¾
    chain = build_joke_evaluator_optimizer()
    
    # æ‰§è¡Œ
    topic = "äººå·¥æ™ºèƒ½"
    state = chain.invoke({"topic": topic})
    
    print(f"\nğŸ‰ æœ€ç»ˆç»“æœ:")
    print(f"è¯é¢˜: {topic}")
    print(f"æœ€ç»ˆç¬‘è¯: {state['joke']}")
    print(f"è¿­ä»£æ¬¡æ•°: {state['iteration_count']}")
    print(f"æœ€ç»ˆè¯„ä¼°: {state['funny_or_not']}")



def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ­ LangGraph ç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨ç¤ºä¾‹")
    print("=" * 60)
    
    # æ£€æŸ¥APIå¯†é’¥
    if config.api_key == "your-openai-api-key":
        print("âš ï¸  è¯·è®¾ç½®æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
        print("   å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ OPENAI_API_KEY è®¾ç½®")
        exit()
    
    # ç›´æ¥è¿è¡Œç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨ç¤ºä¾‹
    print("\nğŸš€ è¿è¡Œç¬‘è¯è¯„ä¼°ä¼˜åŒ–å™¨ç¤ºä¾‹...")
    run_joke_evaluator_optimizer()


if __name__ == "__main__":
    main()
