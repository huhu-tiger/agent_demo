#!/usr/bin/env python3
"""
æ¨¡å‹é…ç½®æ–‡ä»¶
æä¾›å„ç§é¢„è®¾çš„æ¨¡å‹é…ç½®
"""

import os
from typing import Dict, Any
from langgraph_demo.study.langgraph_inmemory_demo import ModelConfig


class ModelConfigs:
    """æ¨¡å‹é…ç½®é›†åˆ"""
    
    @staticmethod
    def get_openai_configs() -> Dict[str, ModelConfig]:
        """è·å–OpenAIç›¸å…³é…ç½®"""
        api_key = os.environ.get("OPENAI_API_KEY")
        
        return {
            "gpt-4o-mini": ModelConfig(
                model_name="gpt-4o-mini",
                model_provider="openai",
                api_key=api_key,
                embedding_model="text-embedding-3-small",
                embedding_provider="openai"
            ),
            "gpt-4o": ModelConfig(
                model_name="gpt-4o",
                model_provider="openai",
                api_key=api_key,
                embedding_model="text-embedding-3-small",
                embedding_provider="openai"
            ),
            "gpt-3.5-turbo": ModelConfig(
                model_name="gpt-3.5-turbo",
                model_provider="openai",
                api_key=api_key,
                embedding_model="text-embedding-ada-002",
                embedding_provider="openai"
            ),
            "gpt-4-turbo": ModelConfig(
                model_name="gpt-4-turbo-preview",
                model_provider="openai",
                api_key=api_key,
                embedding_model="text-embedding-3-small",
                embedding_provider="openai"
            )
        }
    
    @staticmethod
    def get_azure_configs() -> Dict[str, ModelConfig]:
        """è·å–Azure OpenAIé…ç½®"""
        api_key = os.environ.get("AZURE_OPENAI_API_KEY")
        endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
        
        if not api_key or not endpoint:
            print("âš ï¸  è¯·è®¾ç½® AZURE_OPENAI_API_KEY å’Œ AZURE_OPENAI_ENDPOINT ç¯å¢ƒå˜é‡")
            return {}
        
        return {
            "azure-gpt-4": ModelConfig(
                model_name="gpt-4",
                model_provider="azure",
                base_url=endpoint,
                api_key=api_key,
                embedding_model="text-embedding-ada-002",
                embedding_provider="azure",
                embedding_base_url=endpoint
            ),
            "azure-gpt-35-turbo": ModelConfig(
                model_name="gpt-35-turbo",
                model_provider="azure",
                base_url=endpoint,
                api_key=api_key,
                embedding_model="text-embedding-ada-002",
                embedding_provider="azure",
                embedding_base_url=endpoint
            )
        }
    
    @staticmethod
    def get_anthropic_configs() -> Dict[str, ModelConfig]:
        """è·å–Anthropicé…ç½®"""
        api_key = os.environ.get("ANTHROPIC_API_KEY")
        
        if not api_key:
            print("âš ï¸  è¯·è®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
            return {}
        
        return {
            "claude-3-opus": ModelConfig(
                model_name="claude-3-opus-20240229",
                model_provider="anthropic",
                api_key=api_key,
                embedding_model="text-embedding-3-small",
                embedding_provider="openai"  # Anthropicæ²¡æœ‰åµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨OpenAI
            ),
            "claude-3-sonnet": ModelConfig(
                model_name="claude-3-sonnet-20240229",
                model_provider="anthropic",
                api_key=api_key,
                embedding_model="text-embedding-3-small",
                embedding_provider="openai"
            ),
            "claude-3-haiku": ModelConfig(
                model_name="claude-3-haiku-20240307",
                model_provider="anthropic",
                api_key=api_key,
                embedding_model="text-embedding-3-small",
                embedding_provider="openai"
            )
        }
    
    @staticmethod
    def get_local_configs() -> Dict[str, ModelConfig]:
        """è·å–æœ¬åœ°æ¨¡å‹é…ç½®"""
        return {
            "ollama-llama2": ModelConfig(
                model_name="llama2",
                model_provider="ollama",
                base_url="http://localhost:11434",
                embedding_model="nomic-embed-text",
                embedding_provider="ollama",
                embedding_base_url="http://localhost:11434"
            ),
            "ollama-mistral": ModelConfig(
                model_name="mistral",
                model_provider="ollama",
                base_url="http://localhost:11434",
                embedding_model="nomic-embed-text",
                embedding_provider="ollama",
                embedding_base_url="http://localhost:11434"
            ),
            "ollama-codellama": ModelConfig(
                model_name="codellama",
                model_provider="ollama",
                base_url="http://localhost:11434",
                embedding_model="nomic-embed-text",
                embedding_provider="ollama",
                embedding_base_url="http://localhost:11434"
            )
        }
    
    @staticmethod
    def get_custom_configs() -> Dict[str, ModelConfig]:
        """è·å–è‡ªå®šä¹‰é…ç½®"""
        return {
            "dashscope-qwen": ModelConfig(
                model_name="qwen-turbo",
                model_provider="dashscope",
                base_url="https://dashscope.aliyuncs.com/api/v1",
                api_key=os.environ.get("DASHSCOPE_API_KEY"),
                embedding_model="text-embedding-v1",
                embedding_provider="dashscope",
                embedding_base_url="https://dashscope.aliyuncs.com/api/v1"
            ),
            "zhipu-glm": ModelConfig(
                model_name="glm-4",
                model_provider="zhipuai",
                api_key=os.environ.get("ZHIPU_API_KEY"),
                embedding_model="embedding-2",
                embedding_provider="zhipuai"
            )
        }
    
    @staticmethod
    def get_all_configs() -> Dict[str, ModelConfig]:
        """è·å–æ‰€æœ‰é…ç½®"""
        all_configs = {}
        
        # åˆå¹¶æ‰€æœ‰é…ç½®
        all_configs.update(ModelConfigs.get_openai_configs())
        all_configs.update(ModelConfigs.get_azure_configs())
        all_configs.update(ModelConfigs.get_anthropic_configs())
        all_configs.update(ModelConfigs.get_local_configs())
        all_configs.update(ModelConfigs.get_custom_configs())
        
        return all_configs
    
    @staticmethod
    def list_available_configs():
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é…ç½®"""
        print("ğŸ“‹ å¯ç”¨çš„æ¨¡å‹é…ç½®:")
        print("=" * 50)
        
        configs = ModelConfigs.get_all_configs()
        
        for name, config in configs.items():
            print(f"\nğŸ”§ {name}:")
            print(f"   èŠå¤©æ¨¡å‹: {config.model_provider}:{config.model_name}")
            print(f"   åµŒå…¥æ¨¡å‹: {config.embedding_provider}:{config.embedding_model}")
            if config.base_url:
                print(f"   èŠå¤©APIåœ°å€: {config.base_url}")
            if config.embedding_base_url:
                print(f"   åµŒå…¥APIåœ°å€: {config.embedding_base_url}")
    
    @staticmethod
    def get_config_by_name(name: str) -> ModelConfig:
        """æ ¹æ®åç§°è·å–é…ç½®"""
        configs = ModelConfigs.get_all_configs()
        
        if name not in configs:
            available = list(configs.keys())
            raise ValueError(f"é…ç½® '{name}' ä¸å­˜åœ¨ã€‚å¯ç”¨é…ç½®: {available}")
        
        return configs[name]


def create_custom_config(
    model_name: str,
    model_provider: str,
    base_url: str = None,
    api_key: str = None,
    embedding_model: str = "text-embedding-3-small",
    embedding_provider: str = "openai",
    embedding_base_url: str = None,
    embedding_api_key: str = None
) -> ModelConfig:
    """
    åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    
    Args:
        model_name: èŠå¤©æ¨¡å‹åç§°
        model_provider: èŠå¤©æ¨¡å‹æä¾›å•†
        base_url: èŠå¤©æ¨¡å‹APIåŸºç¡€URL
        api_key: APIå¯†é’¥
        embedding_model: åµŒå…¥æ¨¡å‹åç§°
        embedding_provider: åµŒå…¥æ¨¡å‹æä¾›å•†
        embedding_base_url: åµŒå…¥æ¨¡å‹APIåŸºç¡€URL
        embedding_api_key: åµŒå…¥æ¨¡å‹APIå¯†é’¥
        
    Returns:
        ModelConfigå¯¹è±¡
    """
    return ModelConfig(
        model_name=model_name,
        model_provider=model_provider,
        base_url=base_url,
        api_key=api_key,
        embedding_model=embedding_model,
        embedding_provider=embedding_provider,
        embedding_base_url=embedding_base_url,
        embedding_api_key=embedding_api_key
    )


if __name__ == "__main__":
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®
    ModelConfigs.list_available_configs()
    
    print("\n" + "=" * 50)
    print("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    print("from model_configs import ModelConfigs")
    print("config = ModelConfigs.get_config_by_name('gpt-4o-mini')")
    print("demo = LangGraphMemoryDemo(model_config=config)") 