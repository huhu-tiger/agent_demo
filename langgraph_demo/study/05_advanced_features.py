# -*- coding: utf-8 -*-
"""
LangGraph é«˜çº§ç‰¹æ€§ç¤ºä¾‹
å­¦ä¹ è¦ç‚¹ï¼šè®°å¿†ç®¡ç†ã€æ£€æŸ¥ç‚¹ã€å¹¶è¡Œå¤„ç†ã€é”™è¯¯å¤„ç†

ä½œè€…: AI Assistant
æ¥æº: LangGraph å®˜æ–¹æ–‡æ¡£å­¦ä¹ 
"""

import os
import asyncio
import uuid
from typing import TypedDict, List, Dict
from typing_extensions import Annotated

# LangGraph æ ¸å¿ƒç»„ä»¶
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.checkpoint.sqlite import SqliteSaver

# LangChain ç»„ä»¶
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

import config

# è‡ªå®šä¹‰æ¨¡å‹é…ç½®
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# è·å–æ—¥å¿—å™¨
logger = config.logger

# ============================================================================
# é«˜çº§çŠ¶æ€å®šä¹‰
# ============================================================================

class AdvancedState(TypedDict):
    """é«˜çº§çŠ¶æ€ - åŒ…å«è®°å¿†ã€æ£€æŸ¥ç‚¹ã€å¹¶è¡Œå¤„ç†ç­‰ç‰¹æ€§"""
    messages: Annotated[List[HumanMessage | AIMessage], add_messages]
    user_input: str
    session_id: str
    memory_context: List[str]
    parallel_results: Dict[str, str]
    error_log: List[str]
    checkpoint_data: Dict[str, any]
    final_response: str

# ============================================================================
# è®°å¿†ç®¡ç†æ™ºèƒ½ä½“
# ============================================================================

def memory_manager(state: AdvancedState) -> AdvancedState:
    """
    è®°å¿†ç®¡ç†æ™ºèƒ½ä½“ - ç®¡ç†å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡
    å­¦ä¹ è¦ç‚¹ï¼šè®°å¿†ç®¡ç†å’Œä¸Šä¸‹æ–‡ç»´æŠ¤
    """
    logger.info("ğŸ§  è®°å¿†ç®¡ç†æ™ºèƒ½ä½“æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    session_id = state.get("session_id", str(uuid.uuid4()))
    memory_context = state.get("memory_context", [])
    
    # æ›´æ–°è®°å¿†ä¸Šä¸‹æ–‡
    memory_context.append(f"ç”¨æˆ·è¾“å…¥: {user_input}")
    
    # æ¨¡æ‹Ÿè®°å¿†æ£€ç´¢
    if len(memory_context) > 1:
        recent_context = memory_context[-3:]  # ä¿ç•™æœ€è¿‘3æ¡è®°å½•
        logger.info(f"è®°å¿†ä¸Šä¸‹æ–‡: {recent_context}")
    else:
        recent_context = memory_context
    
    return {
        "session_id": session_id,
        "memory_context": memory_context,
        "checkpoint_data": {"memory_updated": True, "context_count": len(memory_context)},
        "messages": [SystemMessage(content=f"è®°å¿†å·²æ›´æ–°ï¼Œä¼šè¯ID: {session_id}")]
    }

# ============================================================================
# å¹¶è¡Œå¤„ç†æ™ºèƒ½ä½“
# ============================================================================

def parallel_processor_1(state: AdvancedState) -> AdvancedState:
    """å¹¶è¡Œå¤„ç†å™¨1 - å¤„ç†ä»»åŠ¡A"""
    logger.info("âš¡ å¹¶è¡Œå¤„ç†å™¨1æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    parallel_results = state.get("parallel_results", {})
    
    # æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†
    result = f"å¤„ç†å™¨1ç»“æœ: åˆ†æäº†'{user_input}'çš„è¯­ä¹‰ç‰¹å¾"
    parallel_results["processor_1"] = result
    
    return {
        "parallel_results": parallel_results,
        "checkpoint_data": {"parallel_1_complete": True}
    }

def parallel_processor_2(state: AdvancedState) -> AdvancedState:
    """å¹¶è¡Œå¤„ç†å™¨2 - å¤„ç†ä»»åŠ¡B"""
    logger.info("âš¡ å¹¶è¡Œå¤„ç†å™¨2æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    parallel_results = state.get("parallel_results", {})
    
    # æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†
    result = f"å¤„ç†å™¨2ç»“æœ: æå–äº†'{user_input}'çš„å…³é”®è¯"
    parallel_results["processor_2"] = result
    
    return {
        "parallel_results": parallel_results,
        "checkpoint_data": {"parallel_2_complete": True}
    }

def parallel_processor_3(state: AdvancedState) -> AdvancedState:
    """å¹¶è¡Œå¤„ç†å™¨3 - å¤„ç†ä»»åŠ¡C"""
    logger.info("âš¡ å¹¶è¡Œå¤„ç†å™¨3æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    parallel_results = state.get("parallel_results", {})
    
    # æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†
    result = f"å¤„ç†å™¨3ç»“æœ: ç”Ÿæˆäº†'{user_input}'çš„æ‘˜è¦"
    parallel_results["processor_3"] = result
    
    return {
        "parallel_results": parallel_results,
        "checkpoint_data": {"parallel_3_complete": True}
    }

# ============================================================================
# é”™è¯¯å¤„ç†æ™ºèƒ½ä½“
# ============================================================================

def error_handler(state: AdvancedState) -> AdvancedState:
    """
    é”™è¯¯å¤„ç†æ™ºèƒ½ä½“ - å¤„ç†å¼‚å¸¸å’Œé”™è¯¯
    å­¦ä¹ è¦ç‚¹ï¼šé”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
    """
    logger.info("ğŸ›¡ï¸ é”™è¯¯å¤„ç†æ™ºèƒ½ä½“æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    error_log = state.get("error_log", [])
    parallel_results = state.get("parallel_results", {})
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
    if not parallel_results:
        error_msg = "å¹¶è¡Œå¤„ç†ç»“æœä¸ºç©ºï¼Œå¯èƒ½å­˜åœ¨å¤„ç†é”™è¯¯"
        error_log.append(error_msg)
        logger.warning(error_msg)
    
    # æ¨¡æ‹Ÿé”™è¯¯æ¢å¤
    if error_log:
        recovery_msg = "å·²æ‰§è¡Œé”™è¯¯æ¢å¤æœºåˆ¶"
        error_log.append(recovery_msg)
        logger.info(recovery_msg)
    
    return {
        "error_log": error_log,
        "checkpoint_data": {"error_handled": True, "error_count": len(error_log)}
    }

# ============================================================================
# ç»“æœèšåˆæ™ºèƒ½ä½“
# ============================================================================

def result_aggregator(state: AdvancedState) -> AdvancedState:
    """
    ç»“æœèšåˆæ™ºèƒ½ä½“ - æ•´åˆæ‰€æœ‰å¹¶è¡Œå¤„ç†ç»“æœ
    å­¦ä¹ è¦ç‚¹ï¼šç»“æœèšåˆå’ŒçŠ¶æ€æ•´åˆ
    """
    logger.info("ğŸ¯ ç»“æœèšåˆæ™ºèƒ½ä½“æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    parallel_results = state.get("parallel_results", {})
    memory_context = state.get("memory_context", [])
    error_log = state.get("error_log", [])
    
    # èšåˆç»“æœ
    final_response = f"åŸºäº'{user_input}'çš„ç»¼åˆå¤„ç†ç»“æœï¼š\n\n"
    
    if parallel_results:
        final_response += "ğŸ“Š å¹¶è¡Œå¤„ç†ç»“æœï¼š\n"
        for processor, result in parallel_results.items():
            final_response += f"â€¢ {result}\n"
    
    if memory_context:
        final_response += f"\nğŸ§  è®°å¿†ä¸Šä¸‹æ–‡ ({len(memory_context)} æ¡è®°å½•)ï¼š\n"
        for i, context in enumerate(memory_context[-3:], 1):
            final_response += f"{i}. {context}\n"
    
    if error_log:
        final_response += f"\nâš ï¸ é”™è¯¯æ—¥å¿— ({len(error_log)} æ¡)ï¼š\n"
        for error in error_log:
            final_response += f"â€¢ {error}\n"
    
    final_response += "\nâœ… å¤„ç†å®Œæˆï¼"
    
    return {
        "final_response": final_response,
        "messages": [AIMessage(content=final_response)]
    }

# ============================================================================
# å·¥ä½œæµæ„å»º
# ============================================================================

def create_advanced_workflow():
    """
    åˆ›å»ºé«˜çº§ç‰¹æ€§å·¥ä½œæµ
    å­¦ä¹ è¦ç‚¹ï¼šå¤æ‚å·¥ä½œæµçš„æ„å»ºå’Œé…ç½®
    """
    logger.info("\n" + "="*60)
    logger.info("ğŸš€ é«˜çº§ç‰¹æ€§å·¥ä½œæµ")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    logger.info("="*60)
    
    # 1. åˆ›å»ºçŠ¶æ€å›¾ï¼ˆå¸¦æ£€æŸ¥ç‚¹ï¼‰
    workflow = StateGraph(AdvancedState)
    
    # 2. æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("memory_manager", memory_manager)
    workflow.add_node("parallel_processor_1", parallel_processor_1)
    workflow.add_node("parallel_processor_2", parallel_processor_2)
    workflow.add_node("parallel_processor_3", parallel_processor_3)
    workflow.add_node("error_handler", error_handler)
    workflow.add_node("result_aggregator", result_aggregator)
    
    # 3. è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("memory_manager")
    
    # 4. æ·»åŠ è¾¹ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
    workflow.add_edge("memory_manager", "parallel_processor_1")
    workflow.add_edge("memory_manager", "parallel_processor_2")
    workflow.add_edge("memory_manager", "parallel_processor_3")
    
    # 5. èšåˆå¹¶è¡Œç»“æœ
    workflow.add_edge("parallel_processor_1", "error_handler")
    workflow.add_edge("parallel_processor_2", "error_handler")
    workflow.add_edge("parallel_processor_3", "error_handler")
    workflow.add_edge("error_handler", "result_aggregator")
    workflow.add_edge("result_aggregator", END)
    
    # 6. ç¼–è¯‘å·¥ä½œæµ
    graph = workflow.compile()
    
    return graph

# ============================================================================
# æ£€æŸ¥ç‚¹ç®¡ç†
# ============================================================================

def create_checkpoint_workflow():
    """
    åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„å·¥ä½œæµ
    å­¦ä¹ è¦ç‚¹ï¼šæ£€æŸ¥ç‚¹çš„ä½¿ç”¨å’Œæ¢å¤
    """
    logger.info("\n" + "="*60)
    logger.info("ğŸ’¾ æ£€æŸ¥ç‚¹å·¥ä½œæµ")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    logger.info("="*60)
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨
    checkpointer = InMemorySaver()
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AdvancedState, checkpointer=checkpointer)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("memory_manager", memory_manager)
    workflow.add_node("result_aggregator", result_aggregator)
    
    # è®¾ç½®è¾¹
    workflow.set_entry_point("memory_manager")
    workflow.add_edge("memory_manager", "result_aggregator")
    workflow.add_edge("result_aggregator", END)
    
    # ç¼–è¯‘
    graph = workflow.compile()
    
    return graph

# ============================================================================
# æµ‹è¯•å‡½æ•°
# ============================================================================

def test_advanced_features():
    """æµ‹è¯•é«˜çº§ç‰¹æ€§"""
    logger.info("ğŸš€ æµ‹è¯• LangGraph é«˜çº§ç‰¹æ€§")
    logger.info(f"æ¨¡å‹é…ç½®: {MODEL_NAME}")
    logger.info(f"API åœ°å€: {os.environ.get('OPENAI_API_BASE', 'é»˜è®¤åœ°å€')}")
    
    # åˆ›å»ºé«˜çº§å·¥ä½œæµ
    graph = create_advanced_workflow()
    
    # æµ‹è¯•è¾“å…¥
    test_inputs = [
        "åˆ†æäººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
        "è®¾è®¡ä¸€ä¸ªæ™ºèƒ½æ¨èç³»ç»Ÿ",
        "æ„å»ºä¸€ä¸ªå¤šæ¨¡æ€AIåº”ç”¨"
    ]
    
    for i, test_input in enumerate(test_inputs, 1):
        logger.info(f"\n--- æµ‹è¯• {i} ---")
        logger.info(f"è¾“å…¥: {test_input}")
        
        try:
            result = graph.invoke({"user_input": test_input})
            logger.info(f"ä¼šè¯ID: {result['session_id']}")
            logger.info(f"å¹¶è¡Œç»“æœæ•°é‡: {len(result['parallel_results'])}")
            logger.info(f"è®°å¿†ä¸Šä¸‹æ–‡æ•°é‡: {len(result['memory_context'])}")
            logger.info(f"é”™è¯¯æ—¥å¿—æ•°é‡: {len(result['error_log'])}")
            logger.info("é«˜çº§ç‰¹æ€§æµ‹è¯•å®Œæˆï¼")
        except Exception as e:
            logger.error(f"é”™è¯¯: {e}")

def test_checkpoint_features():
    """æµ‹è¯•æ£€æŸ¥ç‚¹ç‰¹æ€§"""
    logger.info("\nğŸ’¾ æµ‹è¯•æ£€æŸ¥ç‚¹ç‰¹æ€§")
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹å·¥ä½œæµ
    graph = create_checkpoint_workflow()
    
    # æ¨¡æ‹Ÿæ£€æŸ¥ç‚¹æ¢å¤
    config = {"configurable": {"thread_id": str(uuid.uuid4())}}
    
    test_input = "æµ‹è¯•æ£€æŸ¥ç‚¹åŠŸèƒ½"
    logger.info(f"è¾“å…¥: {test_input}")
    
    try:
        result = graph.invoke({"user_input": test_input}, config=config)
        logger.info(f"æ£€æŸ¥ç‚¹æ•°æ®: {result['checkpoint_data']}")
        logger.info("æ£€æŸ¥ç‚¹æµ‹è¯•å®Œæˆï¼")
    except Exception as e:
        logger.error(f"é”™è¯¯: {e}")

if __name__ == "__main__":
    test_advanced_features()
    test_checkpoint_features() 