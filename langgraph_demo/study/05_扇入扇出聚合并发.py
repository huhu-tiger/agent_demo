# -*- coding: utf-8 -*-
"""
LangGraph æ‰‡å…¥æ‰‡å‡ºç¤ºä¾‹
å­¦ä¹ è¦ç‚¹ï¼šæ‰‡å…¥å’Œæ‰‡å‡ºæ¨¡å¼çš„åˆ›å»ºå’Œä½¿ç”¨

ä½œè€…: AI Assistant
æ¥æº: LangGraph å®˜æ–¹æ–‡æ¡£å­¦ä¹ 
"""

import os
import operator
from typing import TypedDict, List
from typing_extensions import Annotated

# LangGraph æ ¸å¿ƒç»„ä»¶
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# LangChain ç»„ä»¶
from langchain_core.messages import HumanMessage, AIMessage

import config

# è‡ªå®šä¹‰æ¨¡å‹é…ç½®
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# è·å–æ—¥å¿—å™¨
logger = config.logger

# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class EdgeDemoState(TypedDict):
    """è¾¹æ¼”ç¤ºçŠ¶æ€"""
    messages: Annotated[List[HumanMessage | AIMessage], add_messages]
    user_input: str
    current_node:  Annotated[List[str], operator.add] # ä½¿ç”¨ Annotated å¤„ç†å¤šä¸ªå€¼
    edge_history: Annotated[List[str], operator.add]
    response: Annotated[List[str], operator.add]
    parallel_results: Annotated[List[str], operator.add]

# ============================================================================
# èŠ‚ç‚¹å®šä¹‰
# ============================================================================

def node_a(state: EdgeDemoState) -> EdgeDemoState:
    """èŠ‚ç‚¹A"""
    logger.info("ğŸ…°ï¸ èŠ‚ç‚¹Aæ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    edge_history = ["A"]
    
    response = f"èŠ‚ç‚¹Aå¤„ç†: {user_input}"
    
    return {
        "current_node": ["A"],
        "edge_history": edge_history,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

def node_d(state: EdgeDemoState) -> EdgeDemoState:
    """èŠ‚ç‚¹D - åˆå¹¶èŠ‚ç‚¹"""
    logger.info("ğŸ…³ èŠ‚ç‚¹Dæ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    edge_history = ["D"]
    
    # æ”¶é›†å¹¶è¡Œå¤„ç†çš„ç»“æœ
    parallel_results = state.get("parallel_results", [])
    if parallel_results:
        response = f"èŠ‚ç‚¹Dåˆå¹¶ç»“æœ: {user_input} + {' + '.join(parallel_results)}"
    else:
        response = f"èŠ‚ç‚¹Då¤„ç†: {user_input}"
    logger.info(f"èŠ‚ç‚¹Dåˆå¹¶ç»“æœ: {response}")
    return {
        "current_node": ["D"],
        "edge_history": edge_history,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

def final_node(state: EdgeDemoState) -> EdgeDemoState:
    """æœ€ç»ˆèŠ‚ç‚¹"""
    logger.info("ğŸ æœ€ç»ˆèŠ‚ç‚¹æ­£åœ¨å·¥ä½œ...")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    
    user_input = state["user_input"]
    edge_history = ["Final"]
    
    response = f"æœ€ç»ˆèŠ‚ç‚¹å¤„ç†: {user_input}"
    
    return {
        "current_node": ["Final"],
        "edge_history": edge_history,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

def parallel_worker_1(state: EdgeDemoState) -> EdgeDemoState:
    """å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹1"""
    logger.info("ğŸ”§ å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹1æ­£åœ¨å·¥ä½œ...")
    
    user_input = state["user_input"]
    edge_history = ["Worker1"]
    
    # åªæ·»åŠ è‡ªå·±çš„ç»“æœ
    parallel_results = ["Worker1ç»“æœ"]
    
    response = f"Worker1 å¤„ç†: {user_input}"
    logger.info(f"Worker1 ç»“æœ: {response}")
    return {
        "current_node": ["Worker1"],
        "edge_history": edge_history,
        "parallel_results": parallel_results,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

def parallel_worker_2(state: EdgeDemoState) -> EdgeDemoState:
    """å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹2"""
    logger.info("ğŸ”§ å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹2æ­£åœ¨å·¥ä½œ...")
    
    user_input = state["user_input"]
    edge_history = ["Worker2"]
    
    # åªæ·»åŠ è‡ªå·±çš„ç»“æœ
    parallel_results = ["Worker2ç»“æœ"]
    
    response = f"Worker2 å¤„ç†: {user_input}"
    logger.info(f"Worker2 ç»“æœ: {response}")
    return {
        "current_node": ["Worker2"],
        "edge_history": edge_history,
        "parallel_results": parallel_results,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

def parallel_worker_3(state: EdgeDemoState) -> EdgeDemoState:
    """å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹3"""
    logger.info("ğŸ”§ å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹3æ­£åœ¨å·¥ä½œ...")
    
    user_input = state["user_input"]
    edge_history = ["Worker3"]
    
    # åªæ·»åŠ è‡ªå·±çš„ç»“æœ
    parallel_results = ["Worker3ç»“æœ"]
    response = f"Worker3 å¤„ç†: {user_input}"
    logger.info(f"Worker3 ç»“æœ: {response}")

    return {
        "current_node": ["Worker3"],
        "edge_history": edge_history,
        "parallel_results": parallel_results,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

def parallel_worker_2_1(state: EdgeDemoState) -> EdgeDemoState:
    """å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹2çš„åˆ†æ”¯èŠ‚ç‚¹"""
    logger.info("ğŸ”§ å¹¶è¡Œå·¥ä½œèŠ‚ç‚¹2_1æ­£åœ¨å·¥ä½œ...")
    
    user_input = state["user_input"]
    edge_history = ["Worker2_1"]
    
    # åªæ·»åŠ è‡ªå·±çš„ç»“æœï¼Œä¸ç»§æ‰¿çˆ¶èŠ‚ç‚¹çš„ç»“æœ
    parallel_results = ["Worker2_1ç»“æœ"]
    
    response = f"Worker2_1 å¤„ç†: {user_input}"
    logger.info(f"Worker2_1 ç»“æœ: {response}")

    return {
        "current_node": ["Worker2_1"],
        "edge_history": edge_history,
        "parallel_results": parallel_results,
        "response": [response],
        "messages": [AIMessage(content=response)]
    }

# ============================================================================
# æ‰‡å…¥æ‰‡å‡ºç»„åˆæ¼”ç¤º
# ============================================================================

def demo_fan_in_fan_out():
    """
    æ¼”ç¤ºæ‰‡å…¥æ‰‡å‡ºç»„åˆæ¨¡å¼
    
    å…ˆæ‰‡å‡ºå¹¶è¡Œå¤„ç†ï¼Œå†æ‰‡å…¥åˆå¹¶ç»“æœ
    """
    logger.info("\n" + "="*60)
    logger.info("ğŸ”„âš¡ æ‰‡å…¥æ‰‡å‡ºç»„åˆæ¼”ç¤º")
    logger.info("å…ˆæ‰‡å‡ºå¹¶è¡Œå¤„ç†ï¼Œå†æ‰‡å…¥åˆå¹¶ç»“æœ")
    logger.info("="*60)
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(EdgeDemoState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("start_node", node_a)
    workflow.add_node("parallel_1", parallel_worker_1)
    workflow.add_node("parallel_2", parallel_worker_2)
    workflow.add_node("parallel_2_1", parallel_worker_2_1) 
    workflow.add_node("parallel_3", parallel_worker_3)
    workflow.add_node("merge_node", node_d)
    workflow.add_node("final_node", final_node)
    
    # ç»„åˆæ¨¡å¼ç¤ºä¾‹
    logger.info("ğŸ“ æ‰‡å…¥æ‰‡å‡ºç»„åˆ:")
    logger.info("1. æ‰‡å‡º: start_node â†’ parallel_1, parallel_2, parallel_3")
    logger.info("2. æ‰‡å…¥: parallel_1, parallel_2, parallel_3 â†’ merge_node")
    logger.info("3. ç»§ç»­: merge_node â†’ final_node")
    
    workflow.set_entry_point("start_node")
    
    # æ‰‡å‡ºé˜¶æ®µ
    workflow.add_edge("start_node", "parallel_1")
    workflow.add_edge("start_node", "parallel_2")
    workflow.add_edge("start_node", "parallel_3")
    
    workflow.add_edge("parallel_2", "parallel_2_1") # parallel_2çš„åˆ†æ”¯èŠ‚ç‚¹
    # æ‰‡å…¥é˜¶æ®µ
    workflow.add_edge(["parallel_1", "parallel_3", "parallel_2_1"], "merge_node") # ä¿è¯æ‰€æœ‰å¹¶è¡ŒèŠ‚ç‚¹éƒ½æ‰§è¡Œå®Œï¼Œå†åˆå¹¶
    
    # ç»§ç»­å¤„ç†
    workflow.add_edge("merge_node", "final_node")
    workflow.add_edge("final_node", END)
    
    # ç¼–è¯‘å¹¶æµ‹è¯•
    graph = workflow.compile()
        # å¯è§†åŒ–å·¥ä½œæµç¨‹å›¾
    from show_graph import show_workflow_graph
    
    # ç”Ÿæˆå·¥ä½œæµå›¾çš„ PNG æ ¼å¼ï¼Œç”¨äºæ–‡æ¡£å’Œæ¼”ç¤º
    # å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„æ ¼å¼ï¼š
    # - formats=['md']: åªç”Ÿæˆ Markdown æ–‡ä»¶
    # - formats=['mmd']: åªç”Ÿæˆ Mermaid ä»£ç æ–‡ä»¶  
    # - formats=['png']: åªç”Ÿæˆ PNG å›¾ç‰‡
    # - formats=['png', 'md', 'mmd']: ç”Ÿæˆå¤šç§æ ¼å¼
    show_workflow_graph(graph, "æ‰‡å…¥æ‰‡å‡ºå·¥ä½œæµ", logger, "æ‰‡å…¥æ‰‡å‡ºæ¨¡å¼æ¼”ç¤º", formats=['png'])
    test_input = "æ‰‡å…¥æ‰‡å‡ºç»„åˆæµ‹è¯•"
    logger.info(f"\nğŸ§ª æµ‹è¯•è¾“å…¥: {test_input}")
    
    try:
        result = graph.invoke({"user_input": test_input}, config={"configurable": {"thread_id": "foo"},"recursion_limit": 100})
        logger.info(f"æ‰§è¡Œè·¯å¾„: {' â†’ '.join(result['edge_history'])}")
        logger.info(f"å¹¶è¡Œç»“æœ: {result.get('parallel_results', [])}")
        logger.info(f"æœ€ç»ˆå“åº”: {' | '.join(result['response'])}")
    except Exception as e:
        logger.error(f"é”™è¯¯: {e}")

# ============================================================================
# ä¸»æµ‹è¯•å‡½æ•°
# ============================================================================

def test_fan_in_fan_out():
    """æµ‹è¯•æ‰‡å…¥æ‰‡å‡ºæ¨¡å¼"""
    logger.info("ğŸ¯ æµ‹è¯• LangGraph æ‰‡å…¥æ‰‡å‡ºæ¨¡å¼")
    logger.info(f"æ¨¡å‹é…ç½®: {MODEL_NAME}")
    logger.info(f"API åœ°å€: {os.environ.get('OPENAI_API_BASE', 'é»˜è®¤åœ°å€')}")
    
    # æ¼”ç¤ºæ‰‡å…¥æ‰‡å‡ºç»„åˆæ¨¡å¼
    demo_fan_in_fan_out()
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ‰ æ‰‡å…¥æ‰‡å‡ºæ¼”ç¤ºå®Œæˆï¼")
    logger.info("="*60)

if __name__ == "__main__":
    test_fan_in_fan_out() 