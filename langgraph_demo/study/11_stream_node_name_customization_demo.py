# -*- coding: utf-8 -*-
"""
LangGraph èŠ‚ç‚¹åç§°è‡ªå®šä¹‰ç¤ºä¾‹
å­¦ä¹ è¦ç‚¹ï¼šèŠ‚ç‚¹åç§°è·Ÿè¸ªã€è‡ªå®šä¹‰æ˜¾ç¤ºåç§°ã€åŠ¨æ€åç§°é…ç½®
"""

import os
import sys
import time
import json
from typing import TypedDict, Annotated
import operator

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import config

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model=MODEL_NAME,
    temperature=0.1,
    max_tokens=500
)

# å®šä¹‰çŠ¶æ€ç»“æ„
class NodeTrackingState(TypedDict):
    """èŠ‚ç‚¹è·Ÿè¸ªçŠ¶æ€å®šä¹‰"""
    user_input: str                    # ç”¨æˆ·è¾“å…¥
    current_node: str                  # å½“å‰èŠ‚ç‚¹åç§°
    node_display_name: str             # èŠ‚ç‚¹æ˜¾ç¤ºåç§°
    node_description: str              # èŠ‚ç‚¹æè¿°
    execution_log: Annotated[list, operator.add]  # æ‰§è¡Œæ—¥å¿—
    step_count: int                    # æ­¥éª¤è®¡æ•°

# èŠ‚ç‚¹é…ç½®å­—å…¸
NODE_CONFIGS = {
    "data_processor": {
        "display_name": "ğŸ“Š æ•°æ®é¢„å¤„ç†å¼•æ“",
        "description": "æ™ºèƒ½å¤„ç†å’Œåˆ†æè¾“å…¥æ•°æ®",
        "emoji": "ğŸ“Š"
    },
    "ai_analyzer": {
        "display_name": "ğŸ§  AIæ™ºèƒ½åˆ†æå™¨",
        "description": "ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯åˆ†æç”¨æˆ·æ„å›¾",
        "emoji": "ğŸ§ "
    },
    "recommendation_engine": {
        "display_name": "ğŸ¯ æ™ºèƒ½æ¨èå¼•æ“",
        "description": "åŸºäºAIç®—æ³•ç”Ÿæˆä¸ªæ€§åŒ–æ¨è",
        "emoji": "ğŸ¯"
    },
    "response_generator": {
        "display_name": "âœ¨ å“åº”ç”Ÿæˆå™¨",
        "description": "æ•´åˆæ‰€æœ‰ç»“æœç”Ÿæˆæœ€ç»ˆå“åº”",
        "emoji": "âœ¨"
    }
}

def get_node_config(node_name: str) -> dict:
    """è·å–èŠ‚ç‚¹é…ç½®"""
    return NODE_CONFIGS.get(node_name, {
        "display_name": f"ğŸ”§ {node_name}",
        "description": "é»˜è®¤èŠ‚ç‚¹æè¿°",
        "emoji": "ğŸ”§"
    })

def create_node_log(node_name: str, action: str, step_count: int, **kwargs) -> dict:
    """åˆ›å»ºèŠ‚ç‚¹æ—¥å¿—"""
    config = get_node_config(node_name)
    return {
        "step": step_count,
        "node": node_name,
        "display_name": config["display_name"],
        "description": config["description"],
        "emoji": config["emoji"],
        "action": action,
        "timestamp": time.strftime("%H:%M:%S"),
        **kwargs
    }

# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def data_processor_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    æ•°æ®é¢„å¤„ç†èŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šèŠ‚ç‚¹åç§°é…ç½®ã€æ—¥å¿—è®°å½•
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "data_processor"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹æ•°æ®é¢„å¤„ç†",
        step_count=step_count,
        input=user_input
    )
    
    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
    time.sleep(0.2)
    processed_data = f"é¢„å¤„ç†ç»“æœ: {user_input.upper()}"
    
    log_entry["result"] = processed_data
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def ai_analyzer_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    AIåˆ†æèŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šLLMè°ƒç”¨ã€èŠ‚ç‚¹çŠ¶æ€è·Ÿè¸ª
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "ai_analyzer"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹AIåˆ†æ",
        step_count=step_count,
        input=user_input
    )
    
    # ä½¿ç”¨LLMè¿›è¡Œåˆ†æ
    prompt = f"""
è¯·åˆ†æç”¨æˆ·è¾“å…¥: "{user_input}"
æä¾›ç®€è¦çš„åˆ†æç»“æœã€‚
"""
    
    response = llm.invoke([HumanMessage(content=prompt)])
    analysis_result = response.content
    
    log_entry["result"] = analysis_result
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def recommendation_engine_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    æ¨èå¼•æ“èŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šåŠ¨æ€èŠ‚ç‚¹åç§°ã€çŠ¶æ€ä¼ é€’
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "recommendation_engine"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹ç”Ÿæˆæ¨è",
        step_count=step_count,
        input=user_input
    )
    
    # æ¨¡æ‹Ÿæ¨èç”Ÿæˆ
    time.sleep(0.3)
    recommendation = f"åŸºäº '{user_input}' çš„æ¨è: å»ºè®®æ·±å…¥å­¦ä¹ ç›¸å…³æŠ€æœ¯"
    
    log_entry["result"] = recommendation
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def response_generator_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    å“åº”ç”Ÿæˆå™¨èŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šæœ€ç»ˆçŠ¶æ€æ•´åˆã€èŠ‚ç‚¹åç§°å±•ç¤º
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "response_generator"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹ç”Ÿæˆæœ€ç»ˆå“åº”",
        step_count=step_count,
        input=user_input
    )
    
    # ç”Ÿæˆæœ€ç»ˆå“åº”
    final_response = f"""
ğŸ‰ å¤„ç†å®Œæˆï¼

ç”¨æˆ·è¾“å…¥: {user_input}
å¤„ç†æ­¥éª¤: {step_count} æ­¥
å½“å‰èŠ‚ç‚¹: {config["display_name"]}

æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼
"""
    
    log_entry["result"] = final_response
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def create_node_tracking_workflow():
    """åˆ›å»ºèŠ‚ç‚¹è·Ÿè¸ªå·¥ä½œæµ"""
    workflow = StateGraph(NodeTrackingState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("data_processor", data_processor_node)
    workflow.add_node("ai_analyzer", ai_analyzer_node)
    workflow.add_node("recommendation_engine", recommendation_engine_node)
    workflow.add_node("response_generator", response_generator_node)
    
    # è®¾ç½®æµç¨‹
    workflow.set_entry_point("data_processor")
    workflow.add_edge("data_processor", "ai_analyzer")
    workflow.add_edge("ai_analyzer", "recommendation_engine")
    workflow.add_edge("recommendation_engine", "response_generator")
    workflow.add_edge("response_generator", END)
    
    return workflow.compile()

def test_node_name_tracking():
    """æµ‹è¯•èŠ‚ç‚¹åç§°è·Ÿè¸ªåŠŸèƒ½"""
    print("ğŸš€ èŠ‚ç‚¹åç§°è·Ÿè¸ªæµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºå·¥ä½œæµ
    graph = create_node_tracking_workflow()
    
    # æµ‹è¯•è¾“å…¥
    user_input = "æˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹"
    
    print(f"ğŸ“ è¾“å…¥: {user_input}")
    print("-" * 40)
    
    # å‡†å¤‡è¾“å…¥çŠ¶æ€
    inputs = {
        "user_input": user_input,
        "execution_log": [],
        "step_count": 0
    }
    
    print("ğŸ” èŠ‚ç‚¹æ‰§è¡Œè·Ÿè¸ª:")
    print("-" * 40)
    
    try:
        # ä½¿ç”¨ updates æ¨¡å¼è·Ÿè¸ªèŠ‚ç‚¹æ‰§è¡Œ
        for chunk in graph.stream(inputs, stream_mode="updates"):
            # æå–èŠ‚ç‚¹ä¿¡æ¯
            for key, value in chunk.items():
                if isinstance(value, dict) and "current_node" in value:
                    node_name = value["current_node"]
                    display_name = value.get("node_display_name", node_name)
                    description = value.get("node_description", "")
                    step_count = value.get("step_count", 0)
                    
                    print(f"ğŸ“ æ­¥éª¤ {step_count}: {display_name}")
                    print(f"   ğŸ“‹ æè¿°: {description}")
                    print(f"   ğŸ”§ èŠ‚ç‚¹å: {node_name}")
                    
                    # æ˜¾ç¤ºèŠ‚ç‚¹æ‰§è¡Œæ—¥å¿—
                    if "execution_log" in value:
                        for log in value["execution_log"]:
                            if log.get("node") == node_name:
                                print(f"   â° æ—¶é—´: {log.get('timestamp', 'N/A')}")
                                print(f"   ğŸ¯ åŠ¨ä½œ: {log.get('action', 'N/A')}")
                                if "result" in log:
                                    result = log["result"]
                                    if len(result) > 80:
                                        result = result[:80] + "..."
                                    print(f"   ğŸ“Š ç»“æœ: {result}")
                                print()
                    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

def show_node_configurations():
    """æ˜¾ç¤ºèŠ‚ç‚¹é…ç½®"""
    print("\nğŸ¨ èŠ‚ç‚¹é…ç½®å±•ç¤º")
    print("=" * 60)
    
    print("å¯ç”¨èŠ‚ç‚¹é…ç½®:")
    for node_name, config in NODE_CONFIGS.items():
        print(f"\n{config['emoji']} {config['display_name']}")
        print(f"   èŠ‚ç‚¹å: {node_name}")
        print(f"   æè¿°: {config['description']}")
    
    print("\né…ç½®ç‰¹ç‚¹:")
    print("âœ… æ”¯æŒä¸­æ–‡æ˜¾ç¤ºåç§°")
    print("âœ… æ”¯æŒemojiè¡¨æƒ…ç¬¦å·")
    print("âœ… è¯¦ç»†çš„èŠ‚ç‚¹æè¿°")
    print("âœ… ç»Ÿä¸€çš„é…ç½®ç®¡ç†")
    print("âœ… åŠ¨æ€èŠ‚ç‚¹ä¿¡æ¯è·å–")

def demonstrate_custom_node_names():
    """æ¼”ç¤ºè‡ªå®šä¹‰èŠ‚ç‚¹åç§°åŠŸèƒ½"""
    print("\nğŸ¯ è‡ªå®šä¹‰èŠ‚ç‚¹åç§°æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå·¥ä½œæµ
    graph = create_node_tracking_workflow()
    
    # æµ‹è¯•è¾“å…¥
    test_inputs = [
        "å¦‚ä½•å­¦ä¹ æœºå™¨å­¦ä¹ ",
        "æ¨èä¸€äº›ç¼–ç¨‹ä¹¦ç±",
        "Pythonæœ‰ä»€ä¹ˆä¼˜åŠ¿"
    ]
    
    for i, user_input in enumerate(test_inputs, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {user_input}")
        print("-" * 40)
        
        # å‡†å¤‡è¾“å…¥çŠ¶æ€
        inputs = {
            "user_input": user_input,
            "execution_log": [],
            "step_count": 0
        }
        
        try:
            # æ‰§è¡Œå·¥ä½œæµå¹¶è·Ÿè¸ªèŠ‚ç‚¹
            node_execution_order = []
            
            for chunk in graph.stream(inputs, stream_mode="updates"):
                for key, value in chunk.items():
                    if isinstance(value, dict) and "current_node" in value:
                        node_name = value["current_node"]
                        display_name = value.get("node_display_name", node_name)
                        step_count = value.get("step_count", 0)
                        
                        if step_count not in [log["step"] for log in node_execution_order]:
                            node_execution_order.append({
                                "step": step_count,
                                "node": node_name,
                                "display_name": display_name
                            })
            
            # æ˜¾ç¤ºæ‰§è¡Œé¡ºåº
            print("æ‰§è¡Œé¡ºåº:")
            for execution in node_execution_order:
                print(f"  {execution['step']}. {execution['display_name']}")
                
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    # æ˜¾ç¤ºèŠ‚ç‚¹é…ç½®
    show_node_configurations()
    
    # æ¼”ç¤ºè‡ªå®šä¹‰èŠ‚ç‚¹åç§°
    # demonstrate_custom_node_names()
    
    # æµ‹è¯•èŠ‚ç‚¹åç§°è·Ÿè¸ª
    test_node_name_tracking()
    
    print("\nâœ… èŠ‚ç‚¹åç§°è‡ªå®šä¹‰ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“š å­¦ä¹ è¦ç‚¹æ€»ç»“:")
    print("1. èŠ‚ç‚¹åç§°é…ç½®: æ”¯æŒä¸­æ–‡ã€emojiå’Œæè¿°")
    print("2. çŠ¶æ€è·Ÿè¸ª: å®æ—¶ç›‘æ§å½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹")
    print("3. æ˜¾ç¤ºåç§°: ç”¨æˆ·å‹å¥½çš„èŠ‚ç‚¹å±•ç¤º")
    print("4. é…ç½®ç®¡ç†: ç»Ÿä¸€çš„èŠ‚ç‚¹é…ç½®å­—å…¸")
    print("5. åŠ¨æ€è·å–: æ ¹æ®èŠ‚ç‚¹åè·å–é…ç½®ä¿¡æ¯")
    print("6. æ‰§è¡Œæ—¥å¿—: è¯¦ç»†çš„èŠ‚ç‚¹æ‰§è¡Œè®°å½•") 