# -*- coding: utf-8 -*-
"""
LangGraph å¤šæ™ºèƒ½ä½“ç¤ºä¾‹ - å­å›¾æ–¹å¼å®ç°
å­¦ä¹ è¦ç‚¹ï¼šå¤šæ™ºèƒ½ä½“æ¶æ„ã€å­å›¾å®ç°ã€çŠ¶æ€ç®¡ç†ã€æœ€ç»ˆç»“æœå…±äº«
å‚è€ƒï¼šhttps://langchain-ai.github.io/langgraph/concepts/multi_agent/#multi-agent-architectures
"""

import os
import sys
import time
import json
from typing import TypedDict, Annotated, Literal
import operator

# æ·»åŠ å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•åˆ°è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥æœ¬ç›®å½•ä¸‹çš„ config.py
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
if CURRENT_DIR not in sys.path:
    sys.path.append(CURRENT_DIR)

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.types import Command
import config

# è·å–æ—¥å¿—å™¨
logger = config.logger
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model=MODEL_NAME,
    temperature=0.1,
    max_tokens=1000
)

# ===== ä¸»å›¾çŠ¶æ€å®šä¹‰ =====
class MainState(TypedDict):
    """ä¸»å›¾çŠ¶æ€"""
    user_input: str                    # ç”¨æˆ·è¾“å…¥
    shared_messages: Annotated[list, operator.add]  # å…±äº«æ¶ˆæ¯åˆ—è¡¨ï¼ˆä»…æœ€ç»ˆç»“æœï¼‰
    current_agent: str                 # å½“å‰æ‰§è¡Œçš„æ™ºèƒ½ä½“
    execution_log: Annotated[list, operator.add]  # æ‰§è¡Œæ—¥å¿—
    step_count: int                    # æ­¥éª¤è®¡æ•°
    next_agent: str                    # ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“
    task_description: str              # ä»»åŠ¡æè¿°

# ===== è§„åˆ’è€…å­å›¾çŠ¶æ€ =====
class PlannerState(TypedDict):
    """è§„åˆ’è€…å­å›¾çŠ¶æ€"""
    user_input: str                    # ç”¨æˆ·è¾“å…¥
    planning_result: str               # è§„åˆ’ç»“æœ
    analysis_notes: list               # åˆ†æç¬”è®°
    planning_start_time: float         # å¼€å§‹æ—¶é—´
    planning_end_time: float           # ç»“æŸæ—¶é—´
    next_agent: str                    # ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“
    task_description: str              # ä»»åŠ¡æè¿°

# ===== ç ”ç©¶è€…å­å›¾çŠ¶æ€ =====
class ResearcherState(TypedDict):
    """ç ”ç©¶è€…å­å›¾çŠ¶æ€"""
    task: str                          # ç ”ç©¶ä»»åŠ¡
    research_result: str               # ç ”ç©¶ç»“æœ
    research_notes: list               # ç ”ç©¶ç¬”è®°
    research_start_time: float         # å¼€å§‹æ—¶é—´
    research_end_time: float           # ç»“æŸæ—¶é—´
    sources: list                      # ä¿¡æ¯æ¥æº

# ===== å†™ä½œè€…å­å›¾çŠ¶æ€ =====
class WriterState(TypedDict):
    """å†™ä½œè€…å­å›¾çŠ¶æ€"""
    requirements: str                  # åˆ›ä½œè¦æ±‚
    research_data: str                 # ç ”ç©¶æ•°æ®
    final_content: str                 # æœ€ç»ˆå†…å®¹
    draft_notes: list                  # è‰ç¨¿ç¬”è®°
    writing_start_time: float          # å¼€å§‹æ—¶é—´
    writing_end_time: float            # ç»“æŸæ—¶é—´

# ===== æ™ºèƒ½ä½“é…ç½® =====
AGENT_CONFIGS = {
    "planner": {
        "name": "ğŸ“‹ ä»»åŠ¡è§„åˆ’è€…",
        "description": "åˆ†æç”¨æˆ·éœ€æ±‚å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’",
        "emoji": "ğŸ“‹",
        "system_prompt": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»»åŠ¡è§„åˆ’è€…ã€‚ä½ çš„èŒè´£æ˜¯ï¼š
1. åˆ†æç”¨æˆ·çš„éœ€æ±‚å’Œé—®é¢˜
2. åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’
3. ç¡®å®šéœ€è¦å“ªäº›ä¸“å®¶æ™ºèƒ½ä½“å‚ä¸
4. ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“åˆ†é…å…·ä½“ä»»åŠ¡

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼è¾“å‡ºä½ çš„è§„åˆ’ç»“æœã€‚"""
    },
    "researcher": {
        "name": "ğŸ” ä¿¡æ¯ç ”ç©¶è€…",
        "description": "æ”¶é›†å’Œåˆ†æç›¸å…³ä¿¡æ¯",
        "emoji": "ğŸ”",
        "system_prompt": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯ç ”ç©¶è€…ã€‚ä½ çš„èŒè´£æ˜¯ï¼š
1. æ ¹æ®ä»»åŠ¡è¦æ±‚æ”¶é›†ç›¸å…³ä¿¡æ¯
2. åˆ†æä¿¡æ¯çš„å¯é æ€§å’Œç›¸å…³æ€§
3. æ•´ç†å’Œæ€»ç»“å…³é”®ä¿¡æ¯
4. æä¾›æœ‰è§åœ°çš„åˆ†æç»“æœ

è¯·æä¾›æ¸…æ™°ã€å‡†ç¡®çš„ç ”ç©¶ç»“æœã€‚"""
    },
    "writer": {
        "name": "âœï¸ å†…å®¹å†™ä½œè€…",
        "description": "æ•´åˆä¿¡æ¯å¹¶ç”Ÿæˆæœ€ç»ˆå†…å®¹",
        "emoji": "âœï¸",
        "system_prompt": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹å†™ä½œè€…ã€‚ä½ çš„èŒè´£æ˜¯ï¼š
1. æ•´åˆæ‰€æœ‰æ”¶é›†åˆ°çš„ä¿¡æ¯
2. æŒ‰ç…§è§„åˆ’è€…çš„è¦æ±‚ç»„ç»‡å†…å®¹
3. ç”Ÿæˆæ¸…æ™°ã€æœ‰é€»è¾‘çš„æœ€ç»ˆè¾“å‡º
4. ç¡®ä¿å†…å®¹çš„å®Œæ•´æ€§å’Œå¯è¯»æ€§

è¯·ç”Ÿæˆé«˜è´¨é‡çš„æœ€ç»ˆå†…å®¹ã€‚"""
    }
}

def get_agent_config(agent_name: str) -> dict:
    """è·å–æ™ºèƒ½ä½“é…ç½®"""
    return AGENT_CONFIGS.get(agent_name, {
        "name": f"ğŸ”§ {agent_name}",
        "description": "é»˜è®¤æ™ºèƒ½ä½“æè¿°",
        "emoji": "ğŸ”§",
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œè¯·å®Œæˆåˆ†é…ç»™ä½ çš„ä»»åŠ¡ã€‚"
    })

def create_execution_log(agent_name: str, action: str, step_count: int, **kwargs) -> dict:
    """åˆ›å»ºæ‰§è¡Œæ—¥å¿—"""
    config = get_agent_config(agent_name)
    return {
        "step": step_count,
        "agent": agent_name,
        "agent_name": config["name"],
        "description": config["description"],
        "emoji": config["emoji"],
        "action": action,
        "timestamp": time.strftime("%H:%M:%S"),
        **kwargs
    }

def print_log(message: str, level: str = "INFO", agent: str = "SYSTEM", line_number: int = None):
    """æ‰“å°æ—¥å¿—"""
    import inspect
    
    # å¦‚æœæ²¡æœ‰æä¾›è¡Œå·ï¼Œè‡ªåŠ¨è·å–è°ƒç”¨ä½ç½®çš„è¡Œå·
    if line_number is None:
        # è·å–è°ƒç”¨æ ˆä¿¡æ¯
        frame = inspect.currentframe()
        # å‘ä¸ŠæŸ¥æ‰¾è°ƒç”¨è€…
        caller_frame = frame.f_back
        if caller_frame:
            line_number = caller_frame.f_lineno
        else:
            line_number = 0
    
    timestamp = time.strftime("%H:%M:%S")
    emoji_map = {
        "INFO": "â„¹ï¸",
        "DEBUG": "ğŸ”",
        "WARNING": "âš ï¸",
        "ERROR": "âŒ",
        "SUCCESS": "âœ…",
        "START": "ğŸš€",
        "END": "ğŸ"
    }
    emoji = emoji_map.get(level, "â„¹ï¸")
    print(f"[{timestamp}] {emoji} [{agent}:L{line_number}] {message}")

# ===== è§„åˆ’è€…å­å›¾èŠ‚ç‚¹å‡½æ•° =====
def planner_analyzer(state: PlannerState) -> PlannerState:
    """è§„åˆ’è€…åˆ†æèŠ‚ç‚¹"""
    user_input = state["user_input"]
    
    print_log(f"å¼€å§‹åˆ†æç”¨æˆ·è¾“å…¥: {user_input[:50]}...", "START", "PLANNER")
    
    # è·å–æ™ºèƒ½ä½“é…ç½®
    config = get_agent_config("planner")
    
    # ä½¿ç”¨LLMè¿›è¡Œä»»åŠ¡åˆ†æ
    prompt = f"""
{config['system_prompt']}

ç”¨æˆ·è¾“å…¥: {user_input}

è¯·åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚è€ƒè™‘ä»¥ä¸‹æ–¹é¢ï¼š
1. ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦
2. éœ€è¦çš„ä¿¡æ¯ç±»å‹
3. æ‰§è¡Œæ­¥éª¤
4. éœ€è¦çš„ä¸“å®¶æ™ºèƒ½ä½“

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºä½ çš„åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
- task_analysis: ä»»åŠ¡åˆ†æ
- execution_plan: æ‰§è¡Œè®¡åˆ’
- required_agents: éœ€è¦çš„æ™ºèƒ½ä½“åˆ—è¡¨
- next_agent: ä¸‹ä¸€ä¸ªåº”è¯¥æ‰§è¡Œçš„æ™ºèƒ½ä½“
- task_description: ç»™ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“çš„ä»»åŠ¡æè¿°
"""
    
    print_log("æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œä»»åŠ¡åˆ†æ...", "INFO", "PLANNER")
    response = llm.invoke([HumanMessage(content=prompt)])
    print_log("LLMåˆ†æå®Œæˆ", "SUCCESS", "PLANNER")
    
    try:
        # å°è¯•è§£æJSONå“åº”
        analysis_result = json.loads(response.content)
        task_description = analysis_result.get("task_description", "æ‰§è¡Œç ”ç©¶ä»»åŠ¡")
        next_agent = analysis_result.get("next_agent", "researcher")
        
        print_log(f"åˆ†æå®Œæˆï¼Œä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“: {next_agent}", "SUCCESS", "PLANNER")
        print_log(f"ä»»åŠ¡æè¿°: {task_description[:50]}...", "INFO", "PLANNER")
        
        return {
            "planning_result": response.content,
            "analysis_notes": [analysis_result],
            "next_agent": next_agent,
            "task_description": task_description
        }
        
    except json.JSONDecodeError:
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        print_log("JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è·¯ç”±", "WARNING", "PLANNER")
        return {
            "planning_result": response.content,
            "analysis_notes": [{"error": "JSONè§£æå¤±è´¥"}],
            "next_agent": "researcher",
            "task_description": "ç ”ç©¶ç”¨æˆ·éœ€æ±‚å¹¶æä¾›ç›¸å…³ä¿¡æ¯"
        }

def planner_finalizer(state: PlannerState) -> PlannerState:
    """è§„åˆ’è€…å®ŒæˆèŠ‚ç‚¹"""
    print_log("è§„åˆ’è€…å­å›¾æ‰§è¡Œå®Œæˆ", "END", "PLANNER")
    return {
        "planning_end_time": time.time()
    }

# ===== ç ”ç©¶è€…å­å›¾èŠ‚ç‚¹å‡½æ•° =====
def researcher_analyzer(state: ResearcherState) -> ResearcherState:
    """ç ”ç©¶è€…åˆ†æèŠ‚ç‚¹"""
    task = state["task"]
    
    print_log(f"å¼€å§‹ç ”ç©¶ä»»åŠ¡: {task[:50]}...", "START", "RESEARCHER")
    
    # è·å–æ™ºèƒ½ä½“é…ç½®
    config = get_agent_config("researcher")
    
    # ä½¿ç”¨LLMè¿›è¡Œç ”ç©¶
    prompt = f"""
{config['system_prompt']}

ç ”ç©¶ä»»åŠ¡: {task}

è¯·è¿›è¡Œæ·±å…¥çš„ç ”ç©¶å’Œåˆ†æï¼Œæä¾›ä»¥ä¸‹å†…å®¹ï¼š
1. ç›¸å…³ä¿¡æ¯æ”¶é›†
2. å…³é”®å‘ç°
3. åˆ†æè§è§£
4. å»ºè®®å’Œæ¨è

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„ç ”ç©¶ç»“æœã€‚
"""
    
    print_log("æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œç ”ç©¶åˆ†æ...", "INFO", "RESEARCHER")
    response = llm.invoke([HumanMessage(content=prompt)])
    research_result = response.content
    print_log("LLMç ”ç©¶å®Œæˆ", "SUCCESS", "RESEARCHER")
    
    print_log(f"ç ”ç©¶ç»“æœé•¿åº¦: {len(research_result)} å­—ç¬¦", "INFO", "RESEARCHER")
    
    return {
        "research_result": research_result,
        "research_notes": [{
            "timestamp": time.strftime("%H:%M:%S"),
            "note": "ç ”ç©¶å®Œæˆï¼Œå‡†å¤‡è½¬ç§»ç»™å†™ä½œè€…"
        }]
    }

def researcher_finalizer(state: ResearcherState) -> ResearcherState:
    """ç ”ç©¶è€…å®ŒæˆèŠ‚ç‚¹"""
    print_log("ç ”ç©¶è€…å­å›¾æ‰§è¡Œå®Œæˆ", "END", "RESEARCHER")
    return {
        "research_end_time": time.time(),
        "sources": ["å†…éƒ¨åˆ†æ", "çŸ¥è¯†åº“", "æ¨ç†"]
    }

# ===== å†™ä½œè€…å­å›¾èŠ‚ç‚¹å‡½æ•° =====
def writer_analyzer(state: WriterState) -> WriterState:
    """å†™ä½œè€…åˆ†æèŠ‚ç‚¹"""
    requirements = state["requirements"]
    research_data = state["research_data"]
    
    print_log(f"å¼€å§‹å†…å®¹åˆ›ä½œï¼Œè¦æ±‚: {requirements[:50]}...", "START", "WRITER")
    
    # è·å–æ™ºèƒ½ä½“é…ç½®
    config = get_agent_config("writer")
    
    # ä½¿ç”¨LLMè¿›è¡Œå†…å®¹åˆ›ä½œ
    prompt = f"""
{config['system_prompt']}

åˆ›ä½œè¦æ±‚: {requirements}

ç ”ç©¶æ•°æ®: {research_data}

è¯·åŸºäºç ”ç©¶æ•°æ®å’Œè¦æ±‚ï¼Œåˆ›ä½œé«˜è´¨é‡çš„æœ€ç»ˆå†…å®¹ã€‚å†…å®¹åº”è¯¥ï¼š
1. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘åˆç†
2. ä¿¡æ¯å‡†ç¡®ï¼Œæ¥æºå¯é 
3. è¯­è¨€æµç•…ï¼Œæ˜“äºç†è§£
4. æ»¡è¶³ç”¨æˆ·éœ€æ±‚

è¯·æä¾›å®Œæ•´çš„æœ€ç»ˆå†…å®¹ã€‚
"""
    
    print_log("æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œå†…å®¹åˆ›ä½œ...", "INFO", "WRITER")
    response = llm.invoke([HumanMessage(content=prompt)])
    final_content = response.content
    print_log("LLMåˆ›ä½œå®Œæˆ", "SUCCESS", "WRITER")
    
    print_log(f"æœ€ç»ˆå†…å®¹é•¿åº¦: {len(final_content)} å­—ç¬¦", "INFO", "WRITER")
    
    return {
        "final_content": final_content,
        "draft_notes": [{
            "timestamp": time.strftime("%H:%M:%S"),
            "note": "å†…å®¹åˆ›ä½œå®Œæˆ"
        }]
    }

def writer_finalizer(state: WriterState) -> WriterState:
    """å†™ä½œè€…å®ŒæˆèŠ‚ç‚¹"""
    print_log("å†™ä½œè€…å­å›¾æ‰§è¡Œå®Œæˆ", "END", "WRITER")
    return {
        "writing_end_time": time.time()
    }

# ===== å­å›¾åˆ›å»ºå‡½æ•° =====
def create_planner_subgraph():
    """åˆ›å»ºè§„åˆ’è€…å­å›¾"""
    print_log("åˆ›å»ºè§„åˆ’è€…å­å›¾", "DEBUG", "SYSTEM")
    workflow = StateGraph(PlannerState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyzer", planner_analyzer)
    workflow.add_node("finalizer", planner_finalizer)
    
    # è®¾ç½®æµç¨‹
    workflow.set_entry_point("analyzer")
    workflow.add_edge("analyzer", "finalizer")
    workflow.add_edge("finalizer", END)
    
    return workflow.compile()

def create_researcher_subgraph():
    """åˆ›å»ºç ”ç©¶è€…å­å›¾"""
    print_log("åˆ›å»ºç ”ç©¶è€…å­å›¾", "DEBUG", "SYSTEM")
    workflow = StateGraph(ResearcherState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyzer", researcher_analyzer)
    workflow.add_node("finalizer", researcher_finalizer)
    
    # è®¾ç½®æµç¨‹
    workflow.set_entry_point("analyzer")
    workflow.add_edge("analyzer", "finalizer")
    workflow.add_edge("finalizer", END)
    
    return workflow.compile()

def create_writer_subgraph():
    """åˆ›å»ºå†™ä½œè€…å­å›¾"""
    print_log("åˆ›å»ºå†™ä½œè€…å­å›¾", "DEBUG", "SYSTEM")
    workflow = StateGraph(WriterState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyzer", writer_analyzer)
    workflow.add_node("finalizer", writer_finalizer)
    
    # è®¾ç½®æµç¨‹
    workflow.set_entry_point("analyzer")
    workflow.add_edge("analyzer", "finalizer")
    workflow.add_edge("finalizer", END)
    
    return workflow.compile()

# ===== ä¸»å›¾èŠ‚ç‚¹å‡½æ•° =====
def main_planner(state: MainState) -> Command[Literal["researcher", "writer", END]]:
    """ä¸»å›¾è§„åˆ’è€…èŠ‚ç‚¹"""
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    
    print_log(f"=== ä¸»å›¾è§„åˆ’è€…èŠ‚ç‚¹æ‰§è¡Œ (æ­¥éª¤ {step_count}) ===", "START", "MAIN")
    print_log(f"ç”¨æˆ·è¾“å…¥: {user_input}", "INFO", "MAIN")
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_execution_log(
        agent_name="planner",
        action="å¼€å§‹ä»»åŠ¡è§„åˆ’",
        step_count=step_count,
        input=user_input
    )
    
    # å‡†å¤‡è§„åˆ’è€…å­å›¾è¾“å…¥
    planner_input = {
        "user_input": user_input,
        "planning_start_time": time.time()
    }
    
    print_log("å‡†å¤‡æ‰§è¡Œè§„åˆ’è€…å­å›¾...", "INFO", "MAIN")
    
    # æ‰§è¡Œè§„åˆ’è€…å­å›¾
    planner_graph = create_planner_subgraph()
    planner_result = planner_graph.invoke(planner_input)
    
    print_log("è§„åˆ’è€…å­å›¾æ‰§è¡Œå®Œæˆ", "SUCCESS", "MAIN")
    
    # æå–ç»“æœ
    next_agent = planner_result.get("next_agent", "researcher")
    task_description = planner_result.get("task_description", "æ‰§è¡Œä»»åŠ¡")
    planning_result = planner_result.get("planning_result", "")
    
    print_log(f"è§„åˆ’ç»“æœ: ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“ = {next_agent}", "INFO", "MAIN")
    print_log(f"ä»»åŠ¡æè¿°: {task_description}", "INFO", "MAIN")
    
    log_entry["result"] = planning_result[:200] + "..." if len(planning_result) > 200 else planning_result
    log_entry["status"] = "completed"
    
    # æ ¹æ®ç»“æœå†³å®šä¸‹ä¸€æ­¥
    if next_agent == "researcher":
        print_log("è·¯ç”±åˆ°ç ”ç©¶è€…æ™ºèƒ½ä½“", "INFO", "MAIN")
        return Command(
            goto="researcher",
            update={
                "current_agent": "researcher",
                "next_agent": next_agent,
                "task_description": task_description,
                "step_count": step_count,
                "execution_log": [log_entry]
            }
        )
    elif next_agent == "writer":
        print_log("è·¯ç”±åˆ°å†™ä½œè€…æ™ºèƒ½ä½“", "INFO", "MAIN")
        return Command(
            goto="writer",
            update={
                "current_agent": "writer",
                "next_agent": next_agent,
                "task_description": task_description,
                "step_count": step_count,
                "execution_log": [log_entry]
            }
        )
    else:
        # å¦‚æœä¸éœ€è¦å…¶ä»–æ™ºèƒ½ä½“ï¼Œç›´æ¥å®Œæˆä»»åŠ¡
        print_log("ç›´æ¥å®Œæˆä»»åŠ¡", "INFO", "MAIN")
        return Command(
            goto=END,
            update={
                "current_agent": "completed",
                "shared_messages": [AIMessage(content=planning_result)],
                "step_count": step_count,
                "execution_log": [log_entry]
            }
        )

def main_researcher(state: MainState) -> Command[Literal["writer", END]]:
    """ä¸»å›¾ç ”ç©¶è€…èŠ‚ç‚¹"""
    step_count = state.get("step_count", 0) + 1
    task_description = state.get("task_description", "æ‰§è¡Œç ”ç©¶ä»»åŠ¡")
    
    print_log(f"=== ä¸»å›¾ç ”ç©¶è€…èŠ‚ç‚¹æ‰§è¡Œ (æ­¥éª¤ {step_count}) ===", "START", "MAIN")
    print_log(f"ç ”ç©¶ä»»åŠ¡: {task_description}", "INFO", "MAIN")
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_execution_log(
        agent_name="researcher",
        action="å¼€å§‹ä¿¡æ¯ç ”ç©¶",
        step_count=step_count,
        task=task_description
    )
    
    # å‡†å¤‡ç ”ç©¶è€…å­å›¾è¾“å…¥
    researcher_input = {
        "task": task_description,
        "research_start_time": time.time()
    }
    
    print_log("å‡†å¤‡æ‰§è¡Œç ”ç©¶è€…å­å›¾...", "INFO", "MAIN")
    
    # æ‰§è¡Œç ”ç©¶è€…å­å›¾
    researcher_graph = create_researcher_subgraph()
    researcher_result = researcher_graph.invoke(researcher_input)
    
    print_log("ç ”ç©¶è€…å­å›¾æ‰§è¡Œå®Œæˆ", "SUCCESS", "MAIN")
    
    # æå–ç»“æœ
    research_result = researcher_result.get("research_result", "")
    
    print_log(f"ç ”ç©¶ç»“æœé•¿åº¦: {len(research_result)} å­—ç¬¦", "INFO", "MAIN")
    
    log_entry["result"] = research_result[:200] + "..." if len(research_result) > 200 else research_result
    log_entry["status"] = "completed"
    
    # å°†ç ”ç©¶ç»“æœæ·»åŠ åˆ°å…±äº«æ¶ˆæ¯ï¼Œç„¶åè½¬ç§»ç»™å†™ä½œè€…
    print_log("è·¯ç”±åˆ°å†™ä½œè€…æ™ºèƒ½ä½“", "INFO", "MAIN")
    return Command(
        goto="writer",
        update={
            "current_agent": "writer",
            "shared_messages": [AIMessage(content=f"ç ”ç©¶ç»“æœ: {research_result[:500]}...")],
            "step_count": step_count,
            "execution_log": [log_entry]
        }
    )

def main_writer(state: MainState) -> Command[Literal[END]]:
    """ä¸»å›¾å†™ä½œè€…èŠ‚ç‚¹"""
    step_count = state.get("step_count", 0) + 1
    task_description = state.get("task_description", "ç”Ÿæˆå†…å®¹")
    
    print_log(f"=== ä¸»å›¾å†™ä½œè€…èŠ‚ç‚¹æ‰§è¡Œ (æ­¥éª¤ {step_count}) ===", "START", "MAIN")
    print_log(f"åˆ›ä½œè¦æ±‚: {task_description}", "INFO", "MAIN")
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_execution_log(
        agent_name="writer",
        action="å¼€å§‹å†…å®¹åˆ›ä½œ",
        step_count=step_count,
        requirements=task_description
    )
    
    # å‡†å¤‡å†™ä½œè€…å­å›¾è¾“å…¥
    writer_input = {
        "requirements": task_description,
        "research_data": "åŸºäºå‰é¢çš„ç ”ç©¶ç»“æœ",
        "writing_start_time": time.time()
    }
    
    print_log("å‡†å¤‡æ‰§è¡Œå†™ä½œè€…å­å›¾...", "INFO", "MAIN")
    
    # æ‰§è¡Œå†™ä½œè€…å­å›¾
    writer_graph = create_writer_subgraph()
    writer_result = writer_graph.invoke(writer_input)
    
    print_log("å†™ä½œè€…å­å›¾æ‰§è¡Œå®Œæˆ", "SUCCESS", "MAIN")
    
    # æå–ç»“æœ
    final_content = writer_result.get("final_content", "")
    
    print_log(f"æœ€ç»ˆå†…å®¹é•¿åº¦: {len(final_content)} å­—ç¬¦", "INFO", "MAIN")
    
    log_entry["result"] = final_content[:200] + "..." if len(final_content) > 200 else final_content
    log_entry["status"] = "completed"
    
    # å®Œæˆä»»åŠ¡ï¼Œå°†æœ€ç»ˆç»“æœæ·»åŠ åˆ°å…±äº«æ¶ˆæ¯
    print_log("ä»»åŠ¡å®Œæˆï¼Œæ·»åŠ åˆ°å…±äº«æ¶ˆæ¯", "SUCCESS", "MAIN")
    return Command(
        goto=END,
        update={
            "current_agent": "completed",
            "shared_messages": [AIMessage(content=final_content)],
            "step_count": step_count,
            "execution_log": [log_entry]
        }
    )

# ===== ä¸»å›¾å·¥ä½œæµåˆ›å»º =====
def create_multi_agent_workflow():
    """åˆ›å»ºå¤šæ™ºèƒ½ä½“å·¥ä½œæµï¼ˆä½¿ç”¨å­å›¾ï¼‰"""
    print_log("åˆ›å»ºå¤šæ™ºèƒ½ä½“å·¥ä½œæµ", "DEBUG", "SYSTEM")
    workflow = StateGraph(MainState)
    
    # æ·»åŠ ä¸»å›¾èŠ‚ç‚¹
    workflow.add_node("planner", main_planner)
    workflow.add_node("researcher", main_researcher)
    workflow.add_node("writer", main_writer)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("planner")
    
    # ç¼–è¯‘å·¥ä½œæµ
    return workflow.compile()

# ===== æµ‹è¯•å’Œæ¼”ç¤ºå‡½æ•° =====
def test_multi_agent_system():
    """æµ‹è¯•å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ"""
    print("\n" + "="*80)
    print("ğŸš€ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæµ‹è¯•ï¼ˆå­å›¾æ–¹å¼ï¼‰")
    print("="*80)
    
    # åˆ›å»ºå·¥ä½œæµ
    print_log("åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“å·¥ä½œæµ", "INFO", "SYSTEM")
    graph = create_multi_agent_workflow()
    
    # æµ‹è¯•è¾“å…¥
    test_inputs = [
        "æˆ‘æƒ³äº†è§£äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
        # "è¯·å¸®æˆ‘åˆ¶å®šä¸€ä¸ªå­¦ä¹ è®¡åˆ’",
        # "åˆ†æå½“å‰ç¼–ç¨‹è¯­è¨€çš„å¸‚åœºéœ€æ±‚"
    ]
    
    for i, user_input in enumerate(test_inputs, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“ æµ‹è¯• {i}: {user_input}")
        print(f"{'='*60}")
        
        # å‡†å¤‡è¾“å…¥çŠ¶æ€
        inputs = {
            "user_input": user_input,
            "shared_messages": [],
            "current_agent": "",
            "execution_log": [],
            "step_count": 0,
            "next_agent": "",
            "task_description": ""
        }
        
        try:
            print_log(f"å¼€å§‹æ‰§è¡Œæµ‹è¯• {i}", "START", "SYSTEM")
            config = {}
            config["thread_id"] = "test"
            # æ‰§è¡Œå·¥ä½œæµ
            print_log("å¼€å§‹æµå¼æ‰§è¡Œå·¥ä½œæµ...", "INFO", "SYSTEM")
            stream_result = graph.stream(inputs, config=config, stream_mode="values")
            
            # å¤„ç†æµå¼ç»“æœ
            final_result = None
            chunk_count = 0
            for chunk in stream_result:
                chunk_count += 1
                print_log(f"æ¥æ”¶åˆ°æµå¼æ•°æ®å— {chunk_count}", "DEBUG", "SYSTEM")
                
                # è·å–æœ€åä¸€ä¸ªchunkä½œä¸ºæœ€ç»ˆç»“æœ
                if isinstance(chunk, dict):
                    final_result = chunk
                    print_log(f"æ•°æ®å— {chunk_count}: å­—å…¸ç±»å‹ï¼ŒåŒ…å« {len(chunk)} ä¸ªé”®", "DEBUG", "SYSTEM")
                else:
                    # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œå°è¯•æå–çŠ¶æ€
                    final_result = getattr(chunk, 'values', chunk)
                    print_log(f"æ•°æ®å— {chunk_count}: å¯¹è±¡ç±»å‹ï¼Œæå–valueså±æ€§", "DEBUG", "SYSTEM")
                
                # æ˜¾ç¤ºå½“å‰æ‰§è¡ŒçŠ¶æ€
                if final_result and isinstance(final_result, dict):
                    current_agent = final_result.get('current_agent', 'unknown')
                    step_count = final_result.get('step_count', 0)
                    if current_agent != 'unknown':
                        print_log(f"å½“å‰æ‰§è¡Œ: {current_agent} (æ­¥éª¤ {step_count})", "INFO", "SYSTEM")
            
            if final_result is None:
                raise Exception("æœªèƒ½è·å–æœ‰æ•ˆçš„æ‰§è¡Œç»“æœ")
            
            print_log(f"æµå¼æ‰§è¡Œå®Œæˆï¼Œå…±å¤„ç† {chunk_count} ä¸ªæ•°æ®å—", "SUCCESS", "SYSTEM")
            print_log(f"æµ‹è¯• {i} æ‰§è¡Œå®Œæˆ", "SUCCESS", "SYSTEM")
            print(f"\nâœ… æ‰§è¡Œå®Œæˆ")
            print(f"ğŸ“Š æ€»æ­¥éª¤æ•°: {final_result.get('step_count', 0)}")
            print(f"ğŸ¤– æœ€ç»ˆæ™ºèƒ½ä½“: {final_result.get('current_agent', 'unknown')}")
            print(f"ğŸ“¦ æµå¼æ•°æ®å—æ•°é‡: {chunk_count}")
            
            # æ˜¾ç¤ºæ‰§è¡Œæ—¥å¿—
            print("\nğŸ“‹ æ‰§è¡Œæ—¥å¿—:")
            for log in final_result.get("execution_log", []):
                print(f"  {log['emoji']} {log['agent_name']}: {log['action']}")
                print(f"     æ—¶é—´: {log['timestamp']}")
                if "result" in log:
                    result_preview = log["result"]
                    if len(result_preview) > 100:
                        result_preview = result_preview[:100] + "..."
                    print(f"     ç»“æœ: {result_preview}")
                print()
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            print("ğŸ¯ æœ€ç»ˆç»“æœ:")
            shared_messages = final_result.get("shared_messages", [])
            for msg in shared_messages:
                if hasattr(msg, 'content'):
                    content = msg.content
                    if len(content) > 300:
                        content = content[:300] + "..."
                    print(f"  {content}")
            
            print(f"\n{'='*60}")
            
        except Exception as e:
            print_log(f"æµ‹è¯• {i} æ‰§è¡Œå¤±è´¥: {e}", "ERROR", "SYSTEM")
            print(f"âŒ é”™è¯¯: {e}")

def demonstrate_subgraph_structure():
    """æ¼”ç¤ºå­å›¾ç»“æ„"""
    print("\nğŸ—ï¸ å­å›¾ç»“æ„æ¼”ç¤º")
    print("=" * 60)
    
    print("ğŸ“‹ è§„åˆ’è€…å­å›¾ç»“æ„:")
    print("  START â†’ analyzer â†’ finalizer â†’ END")
    print("  åŠŸèƒ½: ä»»åŠ¡åˆ†æã€è®¡åˆ’åˆ¶å®šã€è·¯ç”±å†³ç­–")
    
    print("\nğŸ” ç ”ç©¶è€…å­å›¾ç»“æ„:")
    print("  START â†’ analyzer â†’ finalizer â†’ END")
    print("  åŠŸèƒ½: ä¿¡æ¯æ”¶é›†ã€åˆ†æå¤„ç†ã€ç»“æœæ•´ç†")
    
    print("\nâœï¸ å†™ä½œè€…å­å›¾ç»“æ„:")
    print("  START â†’ analyzer â†’ finalizer â†’ END")
    print("  åŠŸèƒ½: å†…å®¹æ•´åˆã€æœ€ç»ˆè¾“å‡ºç”Ÿæˆ")
    
    print("\nğŸ¯ ä¸»å›¾ç»“æ„:")
    print("  START â†’ planner â†’ researcher â†’ writer â†’ END")
    print("  åŠŸèƒ½: æ™ºèƒ½ä½“åè°ƒã€çŠ¶æ€ç®¡ç†ã€ç»“æœèšåˆ")
    
    print("\nğŸ’¡ å­å›¾ä¼˜åŠ¿:")
    print("âœ… æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰ç‹¬ç«‹çš„çŠ¶æ€ç©ºé—´")
    print("âœ… æ”¯æŒå¤æ‚çš„å†…éƒ¨é€»è¾‘å’Œæµç¨‹")
    print("âœ… ä¾¿äºæµ‹è¯•å’Œç»´æŠ¤å•ä¸ªæ™ºèƒ½ä½“")
    print("âœ… å¯ä»¥ç‹¬ç«‹æ‰©å±•å’Œä¼˜åŒ–")
    print("âœ… æ”¯æŒçŠ¶æ€éš”ç¦»å’Œéšç§ä¿æŠ¤")

def show_agent_configurations():
    """æ˜¾ç¤ºæ™ºèƒ½ä½“é…ç½®"""
    print("\nğŸ¨ æ™ºèƒ½ä½“é…ç½®å±•ç¤º")
    print("=" * 60)
    
    print("å¯ç”¨æ™ºèƒ½ä½“é…ç½®:")
    for agent_name, config in AGENT_CONFIGS.items():
        print(f"\n{config['emoji']} {config['name']}")
        print(f"   æ™ºèƒ½ä½“å: {agent_name}")
        print(f"   æè¿°: {config['description']}")
        print(f"   ç³»ç»Ÿæç¤º: {config['system_prompt'][:100]}...")
    
    print("\né…ç½®ç‰¹ç‚¹:")
    print("âœ… æ”¯æŒä¸­æ–‡æ™ºèƒ½ä½“åç§°")
    print("âœ… æ”¯æŒemojiè¡¨æƒ…ç¬¦å·")
    print("âœ… è¯¦ç»†çš„æ™ºèƒ½ä½“æè¿°")
    print("âœ… è‡ªå®šä¹‰ç³»ç»Ÿæç¤º")
    print("âœ… ç»Ÿä¸€çš„é…ç½®ç®¡ç†")

if __name__ == "__main__":
    print("ğŸ¯ LangGraph å¤šæ™ºèƒ½ä½“ç¤ºä¾‹ - å­å›¾æ–¹å¼å®ç°")
    print("=" * 60)
    
    # æ˜¾ç¤ºæ™ºèƒ½ä½“é…ç½®
    show_agent_configurations()
    
    # æ¼”ç¤ºå­å›¾ç»“æ„
    demonstrate_subgraph_structure()
    
    # æµ‹è¯•å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
    test_multi_agent_system()
    
    print("\nâœ… å¤šæ™ºèƒ½ä½“å­å›¾ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“š å­¦ä¹ è¦ç‚¹æ€»ç»“:")
    print("1. å­å›¾æ¶æ„: æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æ˜¯ç‹¬ç«‹çš„å­å›¾")
    print("2. çŠ¶æ€éš”ç¦»: å­å›¾æœ‰ç‹¬ç«‹çš„çŠ¶æ€ç©ºé—´")
    print("3. æ¨¡å—åŒ–è®¾è®¡: ä¾¿äºæµ‹è¯•å’Œç»´æŠ¤")
    print("4. ä¸»å›¾åè°ƒ: ç»Ÿä¸€çš„çŠ¶æ€ç®¡ç†å’Œè·¯ç”±")
    print("5. æœ€ç»ˆç»“æœå…±äº«: æ™ºèƒ½ä½“é—´åªä¼ é€’å¿…è¦ä¿¡æ¯")
    print("6. å¯æ‰©å±•æ€§: æ”¯æŒå¤æ‚çš„å†…éƒ¨é€»è¾‘") 