from typing import Any, TypedDict, List
import uuid

from langchain_core.messages import BaseMessage
from langchain_openai import ChatOpenAI
from langchain_openai.chat_models.base import BaseChatOpenAI

from langchain_core.messages import AnyMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import InMemorySaver
from langmem.short_term import SummarizationNode, RunningSummary


def add_message_ids(messages: List[BaseMessage]) -> List[BaseMessage]:
    """ä¸ºæ¶ˆæ¯æ·»åŠ IDå­—æ®µ"""
    for message in messages:
        if not hasattr(message, 'id') or message.id is None:
            message.id = str(uuid.uuid4())
    return messages


class ChildChatOpenAI(ChatOpenAI):
    def get_num_tokens_from_messages(self, messages: List[BaseMessage]) -> int:
        """
        è‡ªå®šä¹‰tokenè®¡ç®—æ–¹æ³•ï¼Œæ”¯æŒå¤šç§æ¨¡å‹
        ä¼˜å…ˆä½¿ç”¨OpenAIçš„tiktokenï¼Œå¤±è´¥æ—¶ä½¿ç”¨å­—ç¬¦ä¼°ç®—
        """
        try:
            # å°è¯•ä½¿ç”¨OpenAIçš„tiktoken
            model, encoding = self._get_encoding_model()
            if model.startswith("cl100k_base"):
                # è°ƒç”¨ç¥–çˆ¶ç±»çš„å‡½æ•°
                return super(BaseChatOpenAI, self).get_num_tokens_from_messages(messages)
            else:
                return super().get_num_tokens_from_messages(messages)
        except Exception as e:
            # å¦‚æœtiktokenå¤±è´¥ï¼Œä½¿ç”¨å­—ç¬¦ä¼°ç®—
            try:
                contents = []
                for m in messages:
                    if hasattr(m, "content"):
                        content = getattr(m, "content")
                        if isinstance(content, str):
                            contents.append(content)
                        elif isinstance(content, list):
                            # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                            for item in content:
                                if hasattr(item, "text"):
                                    contents.append(getattr(item, "text"))
                                elif isinstance(item, dict) and "text" in item:
                                    contents.append(item["text"])
                        else:
                            contents.append(str(content))
                    elif isinstance(m, dict) and "content" in m:
                        contents.append(str(m["content"]))
                    else:
                        contents.append(str(m))
                
                text = " ".join(contents)
                # ç²—ç•¥ä¼°ç®—ï¼šçº¦æ¯4å­—ç¬¦â‰ˆ1tokenï¼ˆé€‚ç”¨äºä¸­æ–‡å’Œè‹±æ–‡æ··åˆï¼‰
                estimated_tokens = max(1, len(text) // 4)
                print(f"âš ï¸  ä½¿ç”¨å­—ç¬¦ä¼°ç®—tokenæ•°é‡: {estimated_tokens} (æ–‡æœ¬é•¿åº¦: {len(text)})")
                return estimated_tokens
            except Exception as fallback_error:
                print(f"âŒ Tokenè®¡ç®—å®Œå…¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼1: {fallback_error}")
                return 1


def print_messages_summary(messages: List[BaseMessage], title: str = "æ¶ˆæ¯å†…å®¹"):
    """æ‰“å°æ¶ˆæ¯å†…å®¹çš„æ‘˜è¦ä¿¡æ¯"""
    print(f"\nğŸ“‹ {title}:")
    print("-" * 50)
    
    total_chars = 0
    total_messages = len(messages)
    
    for i, message in enumerate(messages, 1):
        if hasattr(message, "content"):
            content = message.content
            if isinstance(content, str):
                chars = len(content)
                total_chars += chars
                # æˆªæ–­æ˜¾ç¤ºé•¿å†…å®¹
                display_content = content[:100] + "..." if len(content) > 100 else content
                print(f"æ¶ˆæ¯{i} ({chars}å­—ç¬¦): {display_content}")
            elif isinstance(content, list):
                # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                for j, item in enumerate(content):
                    if hasattr(item, "text"):
                        text = item.text
                        chars = len(text)
                        total_chars += chars
                        display_text = text[:100] + "..." if len(text) > 100 else text
                        print(f"æ¶ˆæ¯{i}-{j+1} ({chars}å­—ç¬¦): {display_text}")
            else:
                content_str = str(content)
                chars = len(content_str)
                total_chars += chars
                display_content = content_str[:100] + "..." if len(content_str) > 100 else content_str
                print(f"æ¶ˆæ¯{i} ({chars}å­—ç¬¦): {display_content}")
        elif isinstance(message, dict) and "content" in message:
            content = message["content"]
            chars = len(content)
            total_chars += chars
            display_content = content[:100] + "..." if len(content) > 100 else content
            print(f"æ¶ˆæ¯{i} ({chars}å­—ç¬¦): {display_content}")
        else:
            print(f"æ¶ˆæ¯{i}: æ— æ³•è§£æå†…å®¹")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ¶ˆæ¯æ•°é‡: {total_messages}")
    print(f"   æ€»å­—ç¬¦æ•°: {total_chars}")
    print(f"   å¹³å‡å­—ç¬¦æ•°: {total_chars // total_messages if total_messages > 0 else 0}")
    print("-" * 50)


import config
import os
# è‡ªå®šä¹‰æ¨¡å‹é…ç½®
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# è·å–æ—¥å¿—å™¨
logger = config.logger


def search(query: str):
    """Search the web."""
    if "weather" in query.lower():
        return "The weather is sunny in New York, with a high of 104 degrees."
    elif "broadway" in query.lower():
        return "Hamilton is always on!"
    else:
        raise "Not enough information"

tools = [search]

# åˆå§‹åŒ–æ¨¡å‹ - æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹
def create_llm(model_name=None, temperature=0.1):
    """
    åˆ›å»ºLLMå®ä¾‹ï¼Œæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹
    """
    if model_name is None:
        model_name = MODEL_NAME
    
    return ChildChatOpenAI(
        model=model_name,
        temperature=temperature,
        streaming=False
    )

# é»˜è®¤æ¨¡å‹å®ä¾‹
model = create_llm()
summarization_model = model.bind(max_tokens=128)

# åˆ›å»ºå®‰å…¨çš„tokenè®¡æ•°å™¨
def safe_token_counter(messages: List[BaseMessage]) -> int:
    """
    å®‰å…¨çš„tokenè®¡æ•°å™¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„ChildChatOpenAI
    """
    try:
        return model.get_num_tokens_from_messages(messages)
    except Exception as e:
        print(f"âš ï¸  Tokenè®¡æ•°å™¨å¼‚å¸¸ï¼Œä½¿ç”¨å­—ç¬¦ä¼°ç®—: {e}")
        # å­—ç¬¦ä¼°ç®—å›é€€
        try:
            contents = []
            for m in messages:
                if hasattr(m, "content"):
                    content = getattr(m, "content")
                    if isinstance(content, str):
                        contents.append(content)
                    else:
                        contents.append(str(content))
                elif isinstance(m, dict) and "content" in m:
                    contents.append(str(m["content"]))
                else:
                    contents.append(str(m))
            
            text = " ".join(contents)
            return max(1, len(text) // 4)
        except Exception:
            return 1

summarization_node = SummarizationNode(
    token_counter=safe_token_counter,
    model=summarization_model,
    max_tokens=256,
    max_tokens_before_summary=1024,
    max_summary_tokens=128,
)

class State(MessagesState):
    context: dict[str, Any]

class LLMInputState(TypedDict):
    summarized_messages: list[AnyMessage]
    context: dict[str, Any]

def call_model(state: LLMInputState):
    # ä¸ºæ¶ˆæ¯æ·»åŠ ID
    summarized_messages = add_message_ids(state["summarized_messages"])
    
    # æ‰“å°æ‘˜è¦åçš„æ¶ˆæ¯å†…å®¹
    print_messages_summary(summarized_messages, "æ‘˜è¦åçš„æ¶ˆæ¯å†…å®¹")
    
    response = model.bind_tools(tools).invoke(summarized_messages)
    return {"messages": [response]}

# Define a router that determines whether to execute tools or exit
def should_continue(state: MessagesState):
    messages = state["messages"]
    last_message = messages[-1]
    if not last_message.tool_calls:
        return END
    else:
        return "tools"

checkpointer = InMemorySaver()
builder = StateGraph(State)
builder.add_node("summarize_node", summarization_node)
builder.add_node("call_model", call_model)
builder.add_node("tools", ToolNode(tools))
builder.set_entry_point("summarize_node")
builder.add_edge("summarize_node", "call_model")
builder.add_conditional_edges("call_model", should_continue, path_map=["tools", END])
builder.add_edge("tools", "summarize_node")  
graph = builder.compile(checkpointer=checkpointer)

# æµ‹è¯•tokenè®¡ç®—åŠŸèƒ½
def test_token_counter():
    """æµ‹è¯•tokenè®¡ç®—åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•è‡ªå®šä¹‰tokenè®¡ç®—åŠŸèƒ½")
    print("-" * 40)
    
    from langchain_core.messages import HumanMessage, SystemMessage
    
    test_messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"),
        HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"),
        HumanMessage(content="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"),
        HumanMessage(content="æœºå™¨å­¦ä¹ çš„å‘å±•å†ç¨‹å¦‚ä½•ï¼Ÿ")
    ]
    
    # ä¸ºæµ‹è¯•æ¶ˆæ¯æ·»åŠ ID
    test_messages = add_message_ids(test_messages)
    
    try:
        # æµ‹è¯•è‡ªå®šä¹‰tokenè®¡æ•°å™¨
        token_count = safe_token_counter(test_messages)
        print(f"âœ… Tokenè®¡ç®—æˆåŠŸ: {token_count}")
        
        # æµ‹è¯•æ¨¡å‹ç›´æ¥è°ƒç”¨
        model_token_count = model.get_num_tokens_from_messages(test_messages)
        print(f"âœ… æ¨¡å‹Tokenè®¡ç®—æˆåŠŸ: {model_token_count}")
        
        return True
    except Exception as e:
        print(f"âŒ Tokenè®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        return False

# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LangMem é•¿ä¸Šä¸‹æ–‡ç®¡ç†æ¼”ç¤º (è‡ªå®šä¹‰Tokenè®¡ç®—)")
    print("=" * 60)
    
    # æµ‹è¯•tokenè®¡ç®—
    if test_token_counter():
        print("\nâœ… Tokenè®¡ç®—åŠŸèƒ½æ­£å¸¸ï¼Œå¼€å§‹æ¼”ç¤º")
        
        # Invoke the graph
        config = {"configurable": {"thread_id": "1"}}
        
        print("\nğŸ’¬ å¼€å§‹å¯¹è¯æ¼”ç¤º:")
        print("=" * 60)
        
        # åˆ›å»ºé•¿å¯¹è¯æ¶ˆæ¯æ¥è§¦å‘æ‘˜è¦
        long_conversation = [
            "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€‚äººå·¥æ™ºèƒ½è¿™ä¸ªæ¦‚å¿µæœ€æ—©æ˜¯åœ¨ä»€ä¹ˆæ—¶å€™æå‡ºçš„ï¼Ÿ",
            "èƒ½è¯¦ç»†è¯´è¯´æœºå™¨å­¦ä¹ çš„å‘å±•é˜¶æ®µå—ï¼Ÿä»æœ€æ—©çš„ç¬¦å·ä¸»ä¹‰åˆ°ç°åœ¨çš„æ·±åº¦å­¦ä¹ ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ æ˜¯ä»€ä¹ˆæ—¶å€™å…´èµ·çš„ï¼Ÿä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ åœ¨2010å¹´ä»£çªç„¶å˜å¾—è¿™ä¹ˆé‡è¦ï¼Ÿ",
            "ç¥ç»ç½‘ç»œçš„å†å²å¯ä»¥è¿½æº¯åˆ°ä»€ä¹ˆæ—¶å€™ï¼Ÿæœ€æ—©çš„ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ",
            "èƒ½è®²è®²å›¾çµæµ‹è¯•å—ï¼Ÿè¿™ä¸ªæµ‹è¯•æ˜¯å¦‚ä½•åˆ¤æ–­ä¸€ä¸ªæœºå™¨æ˜¯å¦å…·æœ‰æ™ºèƒ½çš„ï¼Ÿ",
            "ä»€ä¹ˆæ˜¯ä¸“å®¶ç³»ç»Ÿï¼Ÿä¸“å®¶ç³»ç»Ÿåœ¨äººå·¥æ™ºèƒ½å‘å±•å²ä¸Šæ‰®æ¼”äº†ä»€ä¹ˆè§’è‰²ï¼Ÿ",
            "è‡ªç„¶è¯­è¨€å¤„ç†çš„å‘å±•å†ç¨‹æ˜¯æ€æ ·çš„ï¼Ÿä»æœ€æ—©çš„è§„åˆ™æ–¹æ³•åˆ°ç°åœ¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œç»å†äº†å“ªäº›é‡è¦é˜¶æ®µï¼Ÿ",
            "è®¡ç®—æœºè§†è§‰çš„å‘å±•å†å²å¦‚ä½•ï¼Ÿä»æœ€æ—©çš„å›¾åƒå¤„ç†åˆ°ç°åœ¨çš„é«˜çº§è§†è§‰ç†è§£ï¼Œæœ‰å“ªäº›å…³é”®æŠ€æœ¯çªç ´ï¼Ÿ",
            "å¼ºåŒ–å­¦ä¹ æ˜¯ä»€ä¹ˆæ—¶å€™æå‡ºçš„ï¼Ÿå¼ºåŒ–å­¦ä¹ ä¸å…¶ä»–æœºå™¨å­¦ä¹ æ–¹æ³•æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ",
            "èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ çš„åŒºåˆ«å—ï¼Ÿå®ƒä»¬å„è‡ªé€‚ç”¨äºä»€ä¹ˆåœºæ™¯ï¼Ÿ"
        ]
        
        for i, message in enumerate(long_conversation, 1):
            print(f"\nğŸ”„ ç¬¬{i}è½®å¯¹è¯:")
            print("=" * 50)
            
            # æ‰“å°åŸå§‹æ¶ˆæ¯
            print(f"ç”¨æˆ·è¾“å…¥: {message}")
            
            # è·å–å½“å‰çŠ¶æ€ä¸­çš„æ¶ˆæ¯
            current_state = checkpointer.get(config)
            if current_state and "messages" in current_state:
                current_messages = current_state["messages"]
                print_messages_summary(current_messages, f"å½“å‰å¯¹è¯å†å² (ç¬¬{i}è½®å‰)")
            
            # è°ƒç”¨å›¾
            response = graph.invoke({"messages": message}, config=config)
            
            # æ‰“å°å“åº”
            result = response["messages"][-1].content
            print(f"\nğŸ¤– åŠ©æ‰‹å›å¤: {result}")
            
            # æ¯3è½®æ£€æŸ¥ä¸€æ¬¡æ‘˜è¦çŠ¶æ€
            if i % 3 == 0:
                print(f"\nğŸ“ ç¬¬{i}è½®åçš„æ‘˜è¦çŠ¶æ€:")
                state = checkpointer.get(config)
                if state and "summary" in state:
                    summary = state["summary"]
                    if summary and hasattr(summary, 'summary'):
                        print(f"è¿è¡Œæ‘˜è¦: {summary.summary}")
                        print(f"æ‘˜è¦å­—ç¬¦æ•°: {len(summary.summary)}")
                else:
                    print("æš‚æ— æ‘˜è¦")
            
            print("\n" + "="*50)
        
        print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    else:
        print("\nâŒ Tokenè®¡ç®—åŠŸèƒ½å¼‚å¸¸ï¼Œæ— æ³•ç»§ç»­æ¼”ç¤º")

if __name__ == "__main__":
    main()