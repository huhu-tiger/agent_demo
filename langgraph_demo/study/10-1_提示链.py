"""
LangGraph å¤æ‚æç¤ºé“¾ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphçš„StateGraph APIå®ç°å¤æ‚çš„æç¤ºé“¾å·¥ä½œæµã€‚

ä¸»è¦ç‰¹ç‚¹ï¼š
- ä½¿ç”¨StateGraphæ„å»ºå¤æ‚å·¥ä½œæµ
- çŠ¶æ€ç®¡ç†å’Œæ¡ä»¶è·¯ç”±
- è¿­ä»£ä¼˜åŒ–å’Œè´¨é‡è¯„ä¼°
- ç»“æ„åŒ–è¾“å‡ºå’Œåé¦ˆ
- è‡ªåŠ¨è´¨é‡æ§åˆ¶å’Œæ”¹è¿›
"""

import os
import sys
import time
import uuid
from typing import TypedDict, List, Literal, Optional
from typing_extensions import Annotated
import operator

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥é…ç½®
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

# å¯¼å…¥å¿…è¦çš„åº“
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.pydantic_v1 import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.func import entrypoint, task
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model=config.model,
    temperature=0.1,
    max_tokens=1000
)

# ===== 1. å¤æ‚æç¤ºé“¾ç¤ºä¾‹ (StateGraph API) =====



# å®šä¹‰çŠ¶æ€
class PromptChainState(TypedDict):
    topic: str
    original_content: str
    improved_content: str
    polished_content: str
    quality_score: float
    iteration_count: int
    final_result: str

# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
class QualityFeedback(BaseModel):
    score: float = Field(description="è´¨é‡è¯„åˆ† (0-10)")
    feedback: str = Field(description="æ”¹è¿›å»ºè®®")
    needs_improvement: bool = Field(description="æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›")

# ä¸ºLLMæ·»åŠ ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›
quality_evaluator = llm.with_structured_output(QualityFeedback)

def generate_initial_content(state: PromptChainState) -> PromptChainState:
    """ç”Ÿæˆåˆå§‹å†…å®¹"""
    topic = state["topic"]
    print(f"ğŸ¯ ä¸ºè¯é¢˜ '{topic}' ç”Ÿæˆåˆå§‹å†…å®¹...")
    
    response = llm.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œè€…ã€‚è¯·æ ¹æ®ç»™å®šè¯é¢˜åˆ›ä½œé«˜è´¨é‡çš„å†…å®¹ã€‚"),
        HumanMessage(content=f"è¯·ä¸ºè¯é¢˜ '{topic}' åˆ›ä½œä¸€æ®µæœ‰è¶£ã€æœ‰æ·±åº¦çš„å†…å®¹ã€‚")
    ])
    
    return {"original_content": response.content}

def evaluate_quality(state: PromptChainState) -> PromptChainState:
    """è¯„ä¼°å†…å®¹è´¨é‡"""
    content = state["original_content"]
    print("ğŸ” è¯„ä¼°å†…å®¹è´¨é‡...")
    
    feedback = quality_evaluator.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹çš„è´¨é‡å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚"),
        HumanMessage(content=f"è¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹ï¼š\n\n{content}")
    ])
    
    return {
        "quality_score": feedback.score,
        "iteration_count": state.get("iteration_count", 0) + 1
    }

def improve_content(state: PromptChainState) -> PromptChainState:
    """æ”¹è¿›å†…å®¹"""
    content = state["original_content"]
    print("âœ¨ æ”¹è¿›å†…å®¹...")
    
    response = llm.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹ç¼–è¾‘ã€‚è¯·æ ¹æ®åé¦ˆæ”¹è¿›å†…å®¹ã€‚"),
        HumanMessage(content=f"è¯·æ”¹è¿›ä»¥ä¸‹å†…å®¹ï¼š\n\n{content}")
    ])
    
    return {"improved_content": response.content}

def polish_content(state: PromptChainState) -> PromptChainState:
    """æ¶¦è‰²å†…å®¹"""
    content = state.get("improved_content", state["original_content"])
    print("ğŸ’ æ¶¦è‰²å†…å®¹...")
    
    response = llm.invoke([
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡ˆæ¶¦è‰²ä¸“å®¶ã€‚è¯·å¯¹å†…å®¹è¿›è¡Œæœ€ç»ˆæ¶¦è‰²ã€‚"),
        HumanMessage(content=f"è¯·æ¶¦è‰²ä»¥ä¸‹å†…å®¹ï¼š\n\n{content}")
    ])
    
    return {"polished_content": response.content}

def should_continue(state: PromptChainState) -> Literal["improve", "polish", "end"]:
    """å†³å®šæ˜¯å¦ç»§ç»­æ”¹è¿›"""
    score = state.get("quality_score", 0)
    iteration = state.get("iteration_count", 0)
    
    print(f"ğŸ“Š å½“å‰è´¨é‡è¯„åˆ†: {score}, è¿­ä»£æ¬¡æ•°: {iteration}")
    
    if score >= 8.0:
        return "polish"
    elif iteration < 3:
        return "improve"
    else:
        return "end"

def finalize_result(state: PromptChainState) -> PromptChainState:
    """æœ€ç»ˆåŒ–ç»“æœ"""
    final_content = state.get("polished_content", state.get("improved_content", state["original_content"]))
    print("ğŸ‰ æœ€ç»ˆåŒ–ç»“æœ...")
    
    return {"final_result": final_content}

def build_complex_prompt_chain():
    """æ„å»ºå¤æ‚æç¤ºé“¾å›¾"""
    print("ğŸ—ï¸ æ„å»ºå¤æ‚æç¤ºé“¾å›¾...")
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(PromptChainState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("generate_initial", generate_initial_content)
    workflow.add_node("evaluate_quality", evaluate_quality)
    workflow.add_node("improve_content", improve_content)
    workflow.add_node("polish_content", polish_content)
    workflow.add_node("finalize_result", finalize_result)
    
    # æ·»åŠ è¾¹
    workflow.add_edge(START, "generate_initial")
    workflow.add_edge("generate_initial", "evaluate_quality")
    workflow.add_conditional_edges(
        "evaluate_quality",
        should_continue,
        {
            "improve": "improve_content",
            "polish": "polish_content",
            "end": "finalize_result"
        }
    )
    workflow.add_edge("improve_content", "evaluate_quality")
    workflow.add_edge("polish_content", "finalize_result")
    workflow.add_edge("finalize_result", END)
    
    # ç¼–è¯‘å›¾
    chain = workflow.compile()
    print("âœ… å¤æ‚æç¤ºé“¾å›¾æ„å»ºå®Œæˆï¼")
    
    return chain



# ===== 2. è¿è¡Œç¤ºä¾‹å‡½æ•° =====

def run_complex_example():
    """è¿è¡Œå¤æ‚æç¤ºé“¾ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸš€ å¤æ‚æç¤ºé“¾ç¤ºä¾‹")
    print("=" * 60)
    
    # æ„å»ºå›¾
    chain = build_complex_prompt_chain()
    
    # æ‰§è¡Œ
    topic = "å¯æŒç»­å‘å±•"
    state = chain.invoke({"topic": topic})
    
    print(f"\nğŸ‰ æœ€ç»ˆç»“æœ:")
    print(f"åŸå§‹å†…å®¹: {state['original_content']}")
    print(f"è´¨é‡è¯„åˆ†: {state['quality_score']}")
    print(f"è¿­ä»£æ¬¡æ•°: {state['iteration_count']}")
    print(f"æœ€ç»ˆç»“æœ: {state['final_result']}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ­ LangGraph Prompt Chain ç¤ºä¾‹")
    print("=" * 60)
    
    # æ£€æŸ¥APIå¯†é’¥
    if config.api_key == "your-openai-api-key":
        print("âš ï¸  è¯·è®¾ç½®æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
        print("   å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ OPENAI_API_KEY è®¾ç½®")
        return
    
    # ç›´æ¥è¿è¡Œå¤æ‚æç¤ºé“¾ç¤ºä¾‹
    print("\nğŸš€ è¿è¡Œå¤æ‚æç¤ºé“¾ç¤ºä¾‹...")
    run_complex_example()

if __name__ == "__main__":
    main()
