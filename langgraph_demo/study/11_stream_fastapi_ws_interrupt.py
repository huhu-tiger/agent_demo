# -*- coding: utf-8 -*-
"""
LangGraph èŠ‚ç‚¹åç§°è‡ªå®šä¹‰ç¤ºä¾‹
å­¦ä¹ è¦ç‚¹ï¼šèŠ‚ç‚¹åç§°è·Ÿè¸ªã€è‡ªå®šä¹‰æ˜¾ç¤ºåç§°ã€åŠ¨æ€åç§°é…ç½®
"""

import os
import sys
import time
import json
from typing import TypedDict, Annotated
import operator

# æ·»åŠ å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•åˆ°è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥æœ¬ç›®å½•ä¸‹çš„ config.py
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
if CURRENT_DIR not in sys.path:
    sys.path.append(CURRENT_DIR)

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import config
# è·å–æ—¥å¿—å™¨
logger = config.logger
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = config.base_url
os.environ["OPENAI_API_KEY"] = config.api_key
MODEL_NAME = config.model

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model=MODEL_NAME,
    temperature=0.1,
    max_tokens=500
)

# å®šä¹‰çŠ¶æ€ç»“æ„
class NodeTrackingState(TypedDict):
    """èŠ‚ç‚¹è·Ÿè¸ªçŠ¶æ€å®šä¹‰"""
    user_input: str                    # ç”¨æˆ·è¾“å…¥
    current_node: str                  # å½“å‰èŠ‚ç‚¹åç§°
    node_display_name: str             # èŠ‚ç‚¹æ˜¾ç¤ºåç§°
    node_description: str              # èŠ‚ç‚¹æè¿°
    execution_log: Annotated[list, operator.add]  # æ‰§è¡Œæ—¥å¿—
    step_count: int                    # æ­¥éª¤è®¡æ•°

# èŠ‚ç‚¹é…ç½®å­—å…¸
NODE_CONFIGS = {
    "data_processor": {
        "display_name": "ğŸ“Š æ•°æ®é¢„å¤„ç†å¼•æ“",
        "description": "æ™ºèƒ½å¤„ç†å’Œåˆ†æè¾“å…¥æ•°æ®",
        "emoji": "ğŸ“Š"
    },
    "ai_analyzer": {
        "display_name": "ğŸ§  AIæ™ºèƒ½åˆ†æå™¨",
        "description": "ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯åˆ†æç”¨æˆ·æ„å›¾",
        "emoji": "ğŸ§ "
    },
    "recommendation_engine": {
        "display_name": "ğŸ¯ æ™ºèƒ½æ¨èå¼•æ“",
        "description": "åŸºäºAIç®—æ³•ç”Ÿæˆä¸ªæ€§åŒ–æ¨è",
        "emoji": "ğŸ¯"
    },
    "response_generator": {
        "display_name": "âœ¨ å“åº”ç”Ÿæˆå™¨",
        "description": "æ•´åˆæ‰€æœ‰ç»“æœç”Ÿæˆæœ€ç»ˆå“åº”",
        "emoji": "âœ¨"
    }
}

def get_node_config(node_name: str) -> dict:
    """è·å–èŠ‚ç‚¹é…ç½®"""
    return NODE_CONFIGS.get(node_name, {
        "display_name": f"ğŸ”§ {node_name}",
        "description": "é»˜è®¤èŠ‚ç‚¹æè¿°",
        "emoji": "ğŸ”§"
    })

def create_node_log(node_name: str, action: str, step_count: int, **kwargs) -> dict:
    """åˆ›å»ºèŠ‚ç‚¹æ—¥å¿—"""
    config = get_node_config(node_name)
    return {
        "step": step_count,
        "node": node_name,
        "display_name": config["display_name"],
        "description": config["description"],
        "emoji": config["emoji"],
        "action": action,
        "timestamp": time.strftime("%H:%M:%S"),
        **kwargs
    }

# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def data_processor_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    æ•°æ®é¢„å¤„ç†èŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šèŠ‚ç‚¹åç§°é…ç½®ã€æ—¥å¿—è®°å½•
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "data_processor"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹æ•°æ®é¢„å¤„ç†",
        step_count=step_count,
        input=user_input
    )
    
    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
    time.sleep(0.2)
    processed_data = f"é¢„å¤„ç†ç»“æœ: {user_input.upper()}"
    
    log_entry["result"] = processed_data
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def ai_analyzer_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    AIåˆ†æèŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šLLMè°ƒç”¨ã€èŠ‚ç‚¹çŠ¶æ€è·Ÿè¸ª
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "ai_analyzer"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹AIåˆ†æ",
        step_count=step_count,
        input=user_input
    )
    
    # ä½¿ç”¨LLMè¿›è¡Œåˆ†æ
    prompt = f"""
è¯·åˆ†æç”¨æˆ·è¾“å…¥: "{user_input}"
æä¾›ç®€è¦çš„åˆ†æç»“æœã€‚
"""
    
    response = llm.invoke([HumanMessage(content=prompt)])
    analysis_result = response.content
    
    log_entry["result"] = analysis_result
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def recommendation_engine_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    æ¨èå¼•æ“èŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šåŠ¨æ€èŠ‚ç‚¹åç§°ã€çŠ¶æ€ä¼ é€’
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "recommendation_engine"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹ç”Ÿæˆæ¨è",
        step_count=step_count,
        input=user_input
    )
    
    # æ¨¡æ‹Ÿæ¨èç”Ÿæˆ
    time.sleep(0.1)
    recommendation = f"åŸºäº '{user_input}' çš„æ¨è: å»ºè®®æ·±å…¥å­¦ä¹ ç›¸å…³æŠ€æœ¯"
    
    log_entry["result"] = recommendation
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def response_generator_node(state: NodeTrackingState) -> NodeTrackingState:
    """
    å“åº”ç”Ÿæˆå™¨èŠ‚ç‚¹
    å­¦ä¹ è¦ç‚¹ï¼šæœ€ç»ˆçŠ¶æ€æ•´åˆã€èŠ‚ç‚¹åç§°å±•ç¤º
    """
    user_input = state["user_input"]
    step_count = state.get("step_count", 0) + 1
    node_name = "response_generator"
    
    # è·å–èŠ‚ç‚¹é…ç½®
    config = get_node_config(node_name)
    
    # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
    log_entry = create_node_log(
        node_name=node_name,
        action="å¼€å§‹ç”Ÿæˆæœ€ç»ˆå“åº”",
        step_count=step_count,
        input=user_input
    )
    
    # ç”Ÿæˆæœ€ç»ˆå“åº”
    final_response = f"""
ğŸ‰ å¤„ç†å®Œæˆï¼

ç”¨æˆ·è¾“å…¥: {user_input}
å¤„ç†æ­¥éª¤: {step_count} æ­¥
å½“å‰èŠ‚ç‚¹: {config["display_name"]}

æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼
"""
    
    log_entry["result"] = final_response
    log_entry["status"] = "completed"
    
    return {
        "current_node": node_name,
        "node_display_name": config["display_name"],
        "node_description": config["description"],
        "step_count": step_count,
        "execution_log": [log_entry]
    }

def create_node_tracking_workflow():
    """åˆ›å»ºèŠ‚ç‚¹è·Ÿè¸ªå·¥ä½œæµ"""
    workflow = StateGraph(NodeTrackingState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("data_processor", data_processor_node)
    workflow.add_node("ai_analyzer", ai_analyzer_node)
    workflow.add_node("recommendation_engine", recommendation_engine_node)
    workflow.add_node("response_generator", response_generator_node)
    
    # è®¾ç½®æµç¨‹
    workflow.set_entry_point("data_processor")
    workflow.add_edge("data_processor", "ai_analyzer")
    workflow.add_edge("ai_analyzer", "recommendation_engine")
    workflow.add_edge("recommendation_engine", "response_generator")
    workflow.add_edge("response_generator", END)
    
    return workflow

# ===== FastAPI åº”ç”¨ä¸ WebSocket/SSE æµå¼æ¥å£ =====
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="LangGraph Streaming API", version="0.1.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºä¸€æ¬¡å·¥ä½œæµï¼Œé¿å…é‡å¤æ„å»º
from langgraph.checkpoint.memory import MemorySaver
_memory_checkpointer = MemorySaver()
# ä»¥å¸¦æ£€æŸ¥ç‚¹çš„å½¢å¼ç¼–è¯‘
graph_app = create_node_tracking_workflow().compile(checkpointer=_memory_checkpointer)

# ====== å¼•å…¥ä¸­æ–­æ‰€éœ€ç±»å‹ ======
from typing import List, Literal
from langgraph.types import Command, interrupt

# ====== åŸºäº 08_interrupt_äººå·¥_demo.py çš„ä¸­æ–­å·¥ä½œæµå®šä¹‰ ======
class InterruptState(TypedDict):
    """
    ä¸­æ–­å·¥ä½œæµçš„çŠ¶æ€å®šä¹‰
    
    çŠ¶æ€å­—æ®µè¯´æ˜ï¼š
    - user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
    - processed_result: å¤„ç†åçš„ç»“æœ
    - steps: æ‰§è¡Œæ­¥éª¤åˆ—è¡¨ï¼ˆä½¿ç”¨operator.addè¿›è¡Œç´¯ç§¯ï¼‰
    - decision: å†³ç­–ç»“æœï¼ˆé€šè¿‡/æ‹’ç»/å¾…å¤„ç†ï¼‰
    - tools_log: å·¥å…·è°ƒç”¨æ—¥å¿—åˆ—è¡¨ï¼ˆä½¿ç”¨operator.addè¿›è¡Œç´¯ç§¯ï¼‰
    - current_node: å½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹åç§°
    """
    user_input: str
    processed_result: str
    steps: Annotated[List[str], operator.add]
    decision: str
    tools_log: Annotated[List[dict], operator.add]
    current_node: str

def _create_interrupt_workflow():
    """
    åˆ›å»ºæ”¯æŒä¸­æ–­åŠŸèƒ½çš„å·¥ä½œæµ
    
    å·¥ä½œæµç‰¹ç‚¹ï¼š
    1. æ”¯æŒäººå·¥å¹²é¢„èŠ‚ç‚¹ï¼Œå¯ä»¥åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æš‚åœç­‰å¾…ç”¨æˆ·è¾“å…¥
    2. åŒ…å«å†³ç­–èŠ‚ç‚¹ï¼Œæ ¹æ®ç”¨æˆ·åé¦ˆå†³å®šåç»­æµç¨‹
    3. æ”¯æŒå·¥å…·è°ƒç”¨ï¼ŒåŒ…å«åˆè§„æ£€æŸ¥ã€æ•°æ®è·å–ã€æ‘˜è¦ç”Ÿæˆç­‰
    4. æ”¯æŒå¤šç§æ‰§è¡Œè·¯å¾„ï¼šé€šè¿‡ã€æ‹’ç»ã€å¾…å¤„ç†
    
    å·¥ä½œæµèŠ‚ç‚¹ï¼š
    - process_input: å¤„ç†è¾“å…¥èŠ‚ç‚¹
    - human_interaction: äººå·¥äº¤äº’èŠ‚ç‚¹ï¼ˆä¸­æ–­ç‚¹ï¼‰
    - decision: å†³ç­–èŠ‚ç‚¹
    - approve: æ‰¹å‡†å¤„ç†èŠ‚ç‚¹
    - reject: æ‹’ç»å¤„ç†èŠ‚ç‚¹
    - finalize: æœ€ç»ˆå¤„ç†èŠ‚ç‚¹
    """
    # ===== æ¨¡æ‹Ÿå·¥å…·ï¼ˆåŒæ­¥è°ƒç”¨ï¼‰ =====
    def tool_check_compliance(text: str) -> dict:
        start_ts = time.time()
        time.sleep(0.05)
        ok = "è¿è§„" not in text
        return {
            "tool": "check_compliance",
            "duration_ms": int((time.time() - start_ts) * 1000),
            "status": "ok",
            "output": {"is_compliant": ok}
        }

    def tool_fetch_external_data(query: str) -> dict:
        start_ts = time.time()
        time.sleep(0.08)
        return {
            "tool": "fetch_external_data",
            "duration_ms": int((time.time() - start_ts) * 1000),
            "status": "ok",
            "output": {"query": query, "data": ["item-a", "item-b"]}
        }

    def tool_generate_summary(payload: dict) -> dict:
        start_ts = time.time()
        time.sleep(0.04)
        summary = f"å…± {len(str(payload))} å­—ç¬¦çš„æ‘˜è¦"
        return {
            "tool": "generate_summary",
            "duration_ms": int((time.time() - start_ts) * 1000),
            "status": "ok",
            "output": {"summary": summary}
        }
    def process_input_node(state: InterruptState) -> InterruptState:
        user_input = state.get("user_input", "")
        return {
            "user_input": user_input,
            "steps": ["process_input"],
            "current_node": "process_input",
        }

    def human_interaction_node(state: InterruptState) -> InterruptState:
        """
        äººå·¥äº¤äº’èŠ‚ç‚¹ - å·¥ä½œæµçš„ä¸­æ–­ç‚¹
        
        åŠŸèƒ½è¯´æ˜ï¼š
        1. è¿™æ˜¯å·¥ä½œæµçš„ä¸­æ–­ç‚¹ï¼Œä¼šæš‚åœæ‰§è¡Œç­‰å¾…äººå·¥å¹²é¢„
        2. å‘ç”¨æˆ·å±•ç¤ºå½“å‰çŠ¶æ€å’Œå¯é€‰é¡¹
        3. ç­‰å¾…ç”¨æˆ·æä¾›åé¦ˆåç»§ç»­æ‰§è¡Œ
        
        ä¸­æ–­æ•°æ®åŒ…å«ï¼š
        - message: æç¤ºä¿¡æ¯
        - current_input: å½“å‰ç”¨æˆ·è¾“å…¥
        - options: å¯é€‰æ‹©çš„é€‰é¡¹åˆ—è¡¨
        
        è¿”å›å€¼ï¼š
        - ç”¨æˆ·åé¦ˆå°†ä½œä¸ºæ–°çš„user_inputç»§ç»­åç»­æµç¨‹
        """
        # æ„å»ºä¸­æ–­æ•°æ®ï¼ŒåŒ…å«æç¤ºä¿¡æ¯å’Œå¯é€‰é¡¹
        interrupt_data = {
            "message": "è¯·æä¾›åé¦ˆä¿¡æ¯",
            "current_input": state.get("user_input", ""),
            "options": ["é€šè¿‡", "æ‹’ç»", "éœ€è¦æ›´å¤šä¿¡æ¯"],
        }
        # è°ƒç”¨interruptå‡½æ•°ï¼Œæš‚åœå·¥ä½œæµç­‰å¾…ç”¨æˆ·è¾“å…¥
        user_feedback = interrupt(interrupt_data)
        return {
            "user_input": user_feedback,        # ç”¨æˆ·åé¦ˆä½œä¸ºæ–°çš„è¾“å…¥
            "steps": ["human_interaction"],     # è®°å½•æ‰§è¡Œæ­¥éª¤
            "current_node": "human_interaction", # å½“å‰èŠ‚ç‚¹
        }

    def decision_node(state: InterruptState) -> Command[Literal["approve", "reject", "finalize"]]:
        """
        å†³ç­–èŠ‚ç‚¹ - æ ¹æ®ç”¨æˆ·åé¦ˆå†³å®šåç»­æµç¨‹
        
        åŠŸèƒ½è¯´æ˜ï¼š
        1. åˆ†æç”¨æˆ·åé¦ˆå†…å®¹ï¼Œåˆ¤æ–­ç”¨æˆ·æ„å›¾
        2. æ ¹æ®æ„å›¾é€‰æ‹©ä¸åŒçš„æ‰§è¡Œè·¯å¾„
        3. ä½¿ç”¨Commandå¯¹è±¡æ§åˆ¶å·¥ä½œæµçš„è·³è½¬
        
        å†³ç­–é€»è¾‘ï¼š
        - åŒ…å«"é€šè¿‡"ã€"åŒæ„"ç­‰å…³é”®è¯ -> è·³è½¬åˆ°approveèŠ‚ç‚¹
        - åŒ…å«"æ‹’ç»"ã€"ä¸åŒæ„"ç­‰å…³é”®è¯ -> è·³è½¬åˆ°rejectèŠ‚ç‚¹
        - å…¶ä»–æƒ…å†µ -> è·³è½¬åˆ°finalizeèŠ‚ç‚¹ï¼ˆå¾…å¤„ç†ï¼‰
        
        è¿”å›å€¼ï¼š
        - Commandå¯¹è±¡ï¼ŒåŒ…å«çŠ¶æ€æ›´æ–°å’Œè·³è½¬ç›®æ ‡
        """
        # è·å–ç”¨æˆ·è¾“å…¥å¹¶è½¬æ¢ä¸ºå°å†™ï¼Œä¾¿äºå…³é”®è¯åŒ¹é…
        user_input = state.get("user_input", "").lower()
        
        # åˆ¤æ–­ç”¨æˆ·æ„å›¾å¹¶è®¾ç½®è·³è½¬ç›®æ ‡
        if any(k in user_input for k in ["é€šè¿‡", "åŒæ„", "approve", "yes", "1"]):
            goto = "approve"      # è·³è½¬åˆ°æ‰¹å‡†èŠ‚ç‚¹
            decision = "approved" # å†³ç­–ç»“æœï¼šå·²æ‰¹å‡†
        elif any(k in user_input for k in ["æ‹’ç»", "ä¸åŒæ„", "reject", "no", "2"]):
            goto = "reject"       # è·³è½¬åˆ°æ‹’ç»èŠ‚ç‚¹
            decision = "rejected" # å†³ç­–ç»“æœï¼šå·²æ‹’ç»
        else:
            goto = "finalize"     # è·³è½¬åˆ°æœ€ç»ˆå¤„ç†èŠ‚ç‚¹
            decision = "pending"  # å†³ç­–ç»“æœï¼šå¾…å¤„ç†
        
        # è¿”å›Commandå¯¹è±¡ï¼ŒåŒ…å«çŠ¶æ€æ›´æ–°å’Œè·³è½¬ç›®æ ‡
        return Command(update={
            "user_input": user_input,    # æ›´æ–°ç”¨æˆ·è¾“å…¥
            "steps": ["decision"],       # è®°å½•æ‰§è¡Œæ­¥éª¤
            "decision": decision,        # è®°å½•å†³ç­–ç»“æœ
            "current_node": "decision",  # å½“å‰èŠ‚ç‚¹
        }, goto=goto)

    def approve_node(state: InterruptState) -> InterruptState:
        """
        æ‰¹å‡†å¤„ç†èŠ‚ç‚¹ - æ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹
        
        åŠŸèƒ½è¯´æ˜ï¼š
        1. å½“ç”¨æˆ·é€‰æ‹©"é€šè¿‡"æ—¶ï¼Œæ‰§è¡Œæ­¤èŠ‚ç‚¹
        2. é¡ºåºè°ƒç”¨å¤šä¸ªå·¥å…·è¿›è¡Œå®Œæ•´å¤„ç†
        3. è®°å½•æ‰€æœ‰å·¥å…·è°ƒç”¨çš„æ—¥å¿—
        4. ç”Ÿæˆæœ€ç»ˆçš„å¤„ç†ç»“æœ
        
        å·¥å…·è°ƒç”¨æµç¨‹ï¼š
        1. åˆè§„æ£€æŸ¥å·¥å…· - æ£€æŸ¥å†…å®¹æ˜¯å¦ç¬¦åˆè§„èŒƒ
        2. å¤–éƒ¨æ•°æ®è·å–å·¥å…· - è·å–ç›¸å…³çš„å¤–éƒ¨æ•°æ®
        3. æ‘˜è¦ç”Ÿæˆå·¥å…· - åŸºäºè¾“å…¥å’Œå¤–éƒ¨æ•°æ®ç”Ÿæˆæ‘˜è¦
        
        è¿”å›å€¼ï¼š
        - åŒ…å«å¤„ç†ç»“æœã€æ‰§è¡Œæ­¥éª¤ã€å·¥å…·æ—¥å¿—å’Œå½“å‰èŠ‚ç‚¹ä¿¡æ¯
        """
        user_input = state.get("user_input", "")
        tools_logs: List[dict] = []  # å·¥å…·è°ƒç”¨æ—¥å¿—åˆ—è¡¨
        
        # é¡ºåºè°ƒç”¨æ¨¡æ‹Ÿå·¥å…·ï¼Œè®°å½•æ¯ä¸ªå·¥å…·çš„è°ƒç”¨ç»“æœ
        log1 = tool_check_compliance(user_input)      # åˆè§„æ£€æŸ¥
        tools_logs.append(log1)
        log2 = tool_fetch_external_data(user_input)   # è·å–å¤–éƒ¨æ•°æ®
        tools_logs.append(log2)
        log3 = tool_generate_summary({"input": user_input, "ext": log2.get("output")})  # ç”Ÿæˆæ‘˜è¦
        tools_logs.append(log3)

        # ç”Ÿæˆæœ€ç»ˆå¤„ç†ç»“æœï¼ŒåŒ…å«æ‘˜è¦ä¿¡æ¯
        processed = f"âœ… å·²æ‰¹å‡†: {user_input} | æ‘˜è¦: {log3['output'].get('summary')}"
        return {
            "processed_result": processed,           # å¤„ç†ç»“æœ
            "steps": ["approve", "tools_called"],   # æ‰§è¡Œæ­¥éª¤
            "tools_log": tools_logs,                # å·¥å…·è°ƒç”¨æ—¥å¿—
            "current_node": "approve",              # å½“å‰èŠ‚ç‚¹
        }

    def reject_node(state: InterruptState) -> InterruptState:
        user_input = state.get("user_input", "")
        return {
            "processed_result": f"âŒ å·²æ‹’ç»: {user_input}",
            "steps": ["reject"],
            "current_node": "reject",
        }

    def finalize_node(state: InterruptState) -> InterruptState:
        user_input = state.get("user_input", "")
        processed_result = f"â³ å¾…å¤„ç†: {user_input}"
        return {
            "processed_result": processed_result,
            "steps": ["finalize"],
            "current_node": "finalize",
        }

    builder = StateGraph(InterruptState)
    builder.add_node("process_input", process_input_node)
    builder.add_node("human_interaction", human_interaction_node)
    builder.add_node("decision", decision_node)
    builder.add_node("approve", approve_node)
    builder.add_node("reject", reject_node)
    builder.add_node("finalize", finalize_node)

    builder.add_edge(START, "process_input")
    builder.add_edge("process_input", "human_interaction")
    builder.add_edge("human_interaction", "decision")
    builder.add_edge("approve", END)
    builder.add_edge("reject", END)
    builder.add_edge("finalize", END)

    return builder

# ä»¥åŒä¸€ä¸ª checkpointer ç¼–è¯‘å¯è·¨æ¶ˆæ¯æ¢å¤
interrupt_graph_app = _create_interrupt_workflow().compile(checkpointer=_memory_checkpointer)

ALLOWED_STREAM_MODES = {"updates", "values", "messages", "debug"}

def _safe_serialize(obj):
    try:
        json.dumps(obj)
        return obj
    except TypeError:
        if isinstance(obj, dict):
            return {k: _safe_serialize(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [_safe_serialize(v) for v in obj]
        return str(obj)

def _format_sse(data: dict, event: str = "message") -> str:
    payload = {"event": event, "data": _safe_serialize(data)}
    return json.dumps(payload, ensure_ascii=False) + "\n"

def _parse_stream_modes(mode_param):
    if not mode_param:
        return ["updates"], []
    raw_list = []
    if isinstance(mode_param, str):
        raw_list = [p.strip() for p in mode_param.replace("|", ",").split(",") if p.strip()]
    elif isinstance(mode_param, (list, tuple, set)):
        for item in mode_param:
            if isinstance(item, str):
                raw_list.extend([p.strip() for p in item.replace("|", ",").split(",") if p.strip()])
    # å»é‡å¹¶æ ¡éªŒ
    uniq = []
    for m in raw_list:
        if m not in uniq:
            uniq.append(m)
    valid = [m for m in uniq if m in ALLOWED_STREAM_MODES]
    invalid = [m for m in uniq if m not in ALLOWED_STREAM_MODES]
    if not valid:
        valid = ["updates"]
    return valid, invalid

def _normalize_content(content):
    """å°†å¤æ‚ message content è§„æ•´ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…ä¸å¯åºåˆ—åŒ–/ä¸å¯å“ˆå¸Œå¯¹è±¡å‘ä¸‹æ¸¸ä¼ æ’­ã€‚"""
    try:
        if content is None:
            return ""
        if isinstance(content, str):
            return content
        if isinstance(content, (int, float, bool)):
            return str(content)
        # LangChain å¸¸è§ï¼šlist[dict|str|obj]
        if isinstance(content, list):
            parts = []
            for item in content:
                if isinstance(item, str):
                    parts.append(item)
                elif isinstance(item, dict):
                    # ä¼˜å…ˆæå– text å­—æ®µ
                    txt = item.get("text") or item.get("content")
                    if isinstance(txt, str):
                        parts.append(txt)
                    else:
                        parts.append(json.dumps(_safe_serialize(item), ensure_ascii=False))
                else:
                    # å…œåº•ä¸ºå­—ç¬¦ä¸²
                    parts.append(str(item))
            return "".join(parts)
        if isinstance(content, dict):
            # å°è¯•æå– textï¼Œå¦åˆ™æ•´ä½“åºåˆ—åŒ–
            txt = content.get("text") or content.get("content")
            if isinstance(txt, str):
                return txt
            return json.dumps(_safe_serialize(content), ensure_ascii=False)
        # å¯¹è±¡ï¼šå°è¯•å– .text/.value/.content ç­‰
        for attr in ("text", "value", "content"):
            if hasattr(content, attr):
                val = getattr(content, attr)
                return _normalize_content(val)
        return str(content)
    except Exception:
        return str(content)

def _extract_message_list(value):
    messages = []
    src = None
    if isinstance(value, dict) and "messages" in value:
        src = value["messages"]
    elif isinstance(value, list):
        src = value
    else:
        src = [value]
    for m in src:
        role = getattr(m, "type", None) or getattr(m, "role", None)
        content = getattr(m, "content", None)
        if isinstance(m, dict):
            role = m.get("type") or m.get("role") or role
            content = m.get("content") or content
        content = _normalize_content(content)
        messages.append({"role": role or "unknown", "content": content})
    return messages

def _iter_node_items(chunk):
    """å…¼å®¹æ€§è¿­ä»£ï¼šå°† chunk ç»Ÿä¸€ä¸º (node_name, node_value) åºåˆ—ã€‚
    æ”¯æŒ dictã€(node, value) å…ƒç»„ã€[(node,value), ...] åˆ—è¡¨ã€æˆ–å…¶å®ƒç±»å‹ã€‚
    """
    if isinstance(chunk, dict):
        for k, v in chunk.items():
            yield k, v
        return
    if isinstance(chunk, tuple):
        if len(chunk) == 2:
            yield chunk[0], chunk[1]
            return
    if isinstance(chunk, list):
        for item in chunk:
            if isinstance(item, tuple) and len(item) == 2:
                yield item[0], item[1]
            elif isinstance(item, dict):
                for k, v in item.items():
                    yield k, v
            else:
                yield "unknown", item
        return
    # å…¶å®ƒæœªçŸ¥ç±»å‹ï¼Œä½œä¸ºå•ä¸ªå€¼è¾“å‡º
    yield "unknown", chunk

def _format_tuple_messages_chunk(msg_obj, meta: dict) -> dict:
    """å°† (MessageChunk/Message, meta) è§„èŒƒåŒ–ä¸ºç»Ÿä¸€è´Ÿè½½ã€‚"""
    node_name = meta.get("langgraph_node") or "unknown"
    cfg = get_node_config(str(node_name))
    content = _normalize_content(getattr(msg_obj, "content", msg_obj))
    role = getattr(msg_obj, "type", None) or getattr(msg_obj, "role", None) or "assistant"
    payload = {
        "node": node_name,
        "display_name": cfg["display_name"],
        "description": cfg["description"],
        "step": meta.get("langgraph_step"),
        "path": meta.get("langgraph_path"),
        "triggers": meta.get("langgraph_triggers"),
        "provider": meta.get("ls_provider"),
        "model": meta.get("ls_model_name"),
        "message": {
            "role": role,
            "content": content
        }
    }
    return payload

def _node_sse_generator(user_input: str, stream_mode = "updates", thread_id: str | None = None, checkpoint: str | None = None, replay_history: bool = True):
    modes, invalid = _parse_stream_modes(stream_mode)
    if invalid:
        yield _format_sse({"warning": "invalid_modes", "ignored": invalid, "allowed": sorted(list(ALLOWED_STREAM_MODES))}, event="warning")
    inputs = {
        "user_input": user_input,
        "execution_log": [],
        "step_count": 0
    }
    # é€ä¼ ä¼šè¯ä¸æ–­ç‚¹é…ç½®
    stream_kwargs = {}
    cfg = {}
    configurable = {}
    if thread_id:
        configurable["thread_id"] = thread_id
    if checkpoint:
        # åŒæ­¥ä¼ é€’ä¸¤ç§å¸¸è§é”®ï¼Œä¾¿äºä¸åŒç‰ˆæœ¬å…¼å®¹
        configurable["checkpoint"] = checkpoint
        configurable["checkpoint_id"] = checkpoint
    if configurable:
        cfg["configurable"] = configurable
    if cfg:
        stream_kwargs["config"] = cfg
        
    logger.info(f"stream_kwargs: {stream_kwargs}")

    # æŒ‰éœ€å›æ”¾å†å²ï¼šå°†å·²æœ‰ execution_log ä»¥ç‹¬ç«‹çš„ history äº‹ä»¶è¾“å‡º

    if replay_history and stream_kwargs.get("config"):
        try:
            snapshot = graph_app.get_state(stream_kwargs["config"])
            logger.info(f"history snapshot: {snapshot}")
            if snapshot and hasattr(snapshot, "values") and isinstance(snapshot.values, dict):
                prev_logs = snapshot.values.get("execution_log")
                if isinstance(prev_logs, list):
                    for hist in prev_logs:
                        node = hist.get("node", "unknown")
                        cfg_node = get_node_config(str(node))
                        out = {
                            "step": hist.get("step"),
                            "node": node,
                            "display_name": cfg_node["display_name"],
                            "description": cfg_node["description"],
                            "timestamp": hist.get("timestamp"),
                            "action": hist.get("action"),
                            "result": (hist.get("result")[:500] + "...") if isinstance(hist.get("result"), str) and len(hist.get("result")) > 500 else hist.get("result"),
                            "thread_id": thread_id,
                            "checkpoint": checkpoint
                        }
                        yield _format_sse(out, event="history")
        except Exception as _e:
            # å†å²å›æ”¾å¤±è´¥å¿½ç•¥
            pass

    try:
        for mode in modes:
            # æ¯ä¸ªæ¨¡å¼çš„èµ·å§‹äº‹ä»¶
            yield _format_sse({"mode": mode, "status": "start", "thread_id": thread_id, "checkpoint": checkpoint}, event="mode_start")
            if mode == "updates":
                for chunk in graph_app.stream(inputs, stream_mode=mode, **stream_kwargs):
                    for key, value in chunk.items():
                        if isinstance(value, dict) and "current_node" in value:
                            node_name = value["current_node"]
                            display_name = value.get("node_display_name", node_name)
                            description = value.get("node_description", "")
                            step_count = value.get("step_count", 0)
                            payload = {
                                "step": step_count,
                                "node": node_name,
                                "display_name": display_name,
                                "description": description,
                                "thread_id": thread_id,
                                "checkpoint": checkpoint
                            }
                            if "execution_log" in value:
                                for log in value["execution_log"]:
                                    if log.get("node") == node_name:
                                        result = log.get("result")
                                        if isinstance(result, str) and len(result) > 500:
                                            result = result[:500] + "..."
                                        payload["log"] = {
                                            "timestamp": log.get("timestamp"),
                                            "action": log.get("action"),
                                            "result": result
                                        }
                                        break
                            yield _format_sse(payload, event="node")
            # elif mode == "messages":
            #     for chunk in graph_app.stream(inputs, stream_mode=mode, **stream_kwargs):
            #         logger.info(f"chunk: {chunk}")
            #         # ä¼˜å…ˆå¤„ç† (msg, meta) å…ƒç»„
            #         if isinstance(chunk, tuple) and len(chunk) == 2 and isinstance(chunk[1], dict):
            #             payload = _format_tuple_messages_chunk(chunk[0], chunk[1])
            #             yield _format_sse(payload, event="node")
            #             continue
            #         # å¤„ç†åˆ—è¡¨ï¼šå¯èƒ½åŒ…å«å¤šä¸ª (msg, meta)
            #         if isinstance(chunk, list):
            #             for item in chunk:
            #                 if isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], dict):
            #                     payload = _format_tuple_messages_chunk(item[0], item[1])
            #                     yield _format_sse(payload, event="node")
            #                 else:
            #                     # å›é€€åˆ°é€šç”¨è§£æ
            #                     for node_name, node_value in _iter_node_items(item):
            #                         derived_name = node_name if isinstance(node_name, str) else (
            #                             node_value.get("langgraph_node") if isinstance(node_value, dict) else "unknown"
            #                         )
            #                         cfg = get_node_config(str(derived_name))
            #                         messages = _extract_message_list(node_value)
            #                         logger.info(f"messages: {messages}")
            #                         logger.info(f"cfg: {cfg}")
            #                         payload = {
            #                             "node": derived_name,
            #                             "display_name": cfg["display_name"],
            #                             "description": cfg["description"],
            #                             "messages": messages,
            #                             "thread_id": thread_id,
            #                             "checkpoint": checkpoint
            #                         }
            #                         yield _format_sse(payload, event="node")
            #             continue
            #         # å…¶å®ƒæƒ…å†µï¼šä½¿ç”¨é€šç”¨è§£æ
            #         for node_name, node_value in _iter_node_items(chunk):
            #             derived_name = node_name if isinstance(node_name, str) else (
            #                 node_value.get("langgraph_node") if isinstance(node_value, dict) else "unknown"
            #             )
            #             cfg = get_node_config(str(derived_name))
            #             messages = _extract_message_list(node_value)
            #             logger.info(f"messages: {messages}")
            #             logger.info(f"cfg: {cfg}")
            #             payload = {
            #                 "node": derived_name,
            #                 "display_name": cfg["display_name"],
            #                 "description": cfg["description"],
            #                 "messages": messages,
            #                 "thread_id": thread_id,
            #                 "checkpoint": checkpoint
            #             }
            #             yield _format_sse(payload, event="node")
            else:
                for chunk in graph_app.stream(inputs, stream_mode=mode, **stream_kwargs):
                    yield _format_sse({"chunk": chunk, "thread_id": thread_id, "checkpoint": checkpoint}, event=mode)
            # æ¯ä¸ªæ¨¡å¼çš„ç»“æŸäº‹ä»¶
            yield _format_sse({"mode": mode, "status": "completed", "thread_id": thread_id, "checkpoint": checkpoint}, event="mode_end")
        yield _format_sse({"status": "completed", "thread_id": thread_id, "checkpoint": checkpoint}, event="end")
    except Exception as e:
        yield _format_sse({"status": "error", "message": str(e)}, event="error")




def _node_sse_generator_interrupt(user_input: str, stream_mode = "updates", thread_id: str | None = None, checkpoint: str | None = None, replay_history: bool = True, resume: str | None = None):
    """
    ä¸­æ–­å·¥ä½œæµçš„ SSE äº‹ä»¶ç”Ÿæˆå™¨
    
    åŠŸèƒ½è¯´æ˜ï¼š
    1. æ”¯æŒå·¥ä½œæµä¸­æ–­å’Œäººå·¥å¹²é¢„æœºåˆ¶
    2. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå¯ä»¥ä»ä¸­æ–­ç‚¹æ¢å¤æ‰§è¡Œ
    3. æ”¯æŒå†å²è®°å½•å›æ”¾ï¼Œæ˜¾ç¤ºä¹‹å‰çš„æ‰§è¡Œæ­¥éª¤
    4. æ”¯æŒå·¥å…·è°ƒç”¨ç»“æœçš„è¯¦ç»†è¾“å‡º
    5. æ”¯æŒè°ƒè¯•æ¨¡å¼ï¼Œæä¾›è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯
    
    å‚æ•°è¯´æ˜ï¼š
    - user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
    - stream_mode: æµå¼æ¨¡å¼ï¼ˆupdates/debugç­‰ï¼‰
    - thread_id: ä¼šè¯IDï¼Œç”¨äºçŠ¶æ€æŒä¹…åŒ–
    - checkpoint: æ£€æŸ¥ç‚¹IDï¼Œç”¨äºæ–­ç‚¹ç»­ä¼ 
    - replay_history: æ˜¯å¦å›æ”¾å†å²è®°å½•
    - resume: æ¢å¤æ•°æ®ï¼Œç”¨äºä»ä¸­æ–­ç‚¹ç»§ç»­æ‰§è¡Œ
    
    è¿”å›äº‹ä»¶ï¼š
    - history: å†å²è®°å½•å›æ”¾
    - mode_start/mode_end: æ¨¡å¼å¼€å§‹/ç»“æŸ
    - debug: è°ƒè¯•ä¿¡æ¯ï¼ˆæ‰§è¡Œå‰åçŠ¶æ€ï¼‰
    - interrupt: å·¥ä½œæµä¸­æ–­ï¼Œç­‰å¾…äººå·¥å¹²é¢„
    - tool: å·¥å…·è°ƒç”¨ç»“æœ
    - result: æœ€ç»ˆå¤„ç†ç»“æœ
    - error: é”™è¯¯ä¿¡æ¯
    - end: æµç¨‹ç»“æŸ
    """
    # æ„å»ºé…ç½®å¯¹è±¡ï¼Œç”¨äºçŠ¶æ€æŒä¹…åŒ–å’Œæ–­ç‚¹ç»­ä¼ 
    cfg = {}
    configurable = {}
    if thread_id:
        configurable["thread_id"] = thread_id  # ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„æ‰§è¡Œä¼šè¯
    if checkpoint:
        configurable["checkpoint"] = checkpoint      # æ£€æŸ¥ç‚¹ID
        configurable["checkpoint_id"] = checkpoint   # å…¼å®¹æ€§ï¼šåŒæ—¶è®¾ç½®ä¸¤ç§é”®å
    if configurable:
        cfg["configurable"] = configurable

    # å†å²è®°å½•å›æ”¾ï¼šå¦‚æœå¯ç”¨ä¸”å­˜åœ¨é…ç½®ï¼Œåˆ™è¾“å‡ºå·²ä¿å­˜çš„æ‰§è¡Œæ­¥éª¤å’Œç»“æœ
    if replay_history and cfg.get("configurable"):
        try:
            # è·å–å½“å‰ä¼šè¯çš„çŠ¶æ€å¿«ç…§
            snapshot = interrupt_graph_app.get_state(cfg)
            if snapshot and hasattr(snapshot, "values") and isinstance(snapshot.values, dict):
                steps = snapshot.values.get("steps") or []           # å·²æ‰§è¡Œçš„æ­¥éª¤åˆ—è¡¨
                processed = snapshot.values.get("processed_result")  # å·²å¤„ç†çš„ç»“æœ
                yield _format_sse({
                    "history_steps": steps,        # å†å²æ­¥éª¤
                    "processed_result": processed, # å†å²ç»“æœ
                    "thread_id": thread_id,        # ä¼šè¯ID
                    "checkpoint": checkpoint,      # æ£€æŸ¥ç‚¹ID
                }, event="history")
        except Exception:
            # å†å²å›æ”¾å¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯ç»§ç»­æ‰§è¡Œ
            pass

    # å‘é€æ¨¡å¼å¼€å§‹äº‹ä»¶
    try:
        yield _format_sse({
            "mode": stream_mode or "updates",  # å½“å‰æµå¼æ¨¡å¼
            "status": "start",                 # çŠ¶æ€ï¼šå¼€å§‹
            "thread_id": thread_id,            # ä¼šè¯ID
            "checkpoint": checkpoint,          # æ£€æŸ¥ç‚¹ID
        }, event="mode_start")
    except Exception:
        pass

    try:
        # è°ƒè¯•æ¨¡å¼ï¼šå‘é€æ‰§è¡Œå‰çš„çŠ¶æ€ä¿¡æ¯
        if (stream_mode or "updates") == "debug":
            yield _format_sse({
                "phase": "before_invoke",      # é˜¶æ®µï¼šæ‰§è¡Œå‰
                "intent": "resume" if (resume is not None and resume != "") else "initial",  # æ„å›¾ï¼šæ¢å¤æˆ–åˆå§‹æ‰§è¡Œ
                "config": cfg,                 # é…ç½®ä¿¡æ¯
                "thread_id": thread_id,        # ä¼šè¯ID
                "checkpoint": checkpoint,      # æ£€æŸ¥ç‚¹ID
            }, event="debug")
        
        # æ ¹æ®æ˜¯å¦æœ‰æ¢å¤æ•°æ®å†³å®šæ‰§è¡Œæ–¹å¼
        if resume is not None and resume != "":
            # æ¢å¤æ‰§è¡Œï¼šä»ä¸­æ–­ç‚¹ç»§ç»­
            result = interrupt_graph_app.invoke(Command(resume=resume), config=cfg)
        else:
            # åˆæ¬¡æ‰§è¡Œï¼šåˆ›å»ºæ–°çš„è¾“å…¥çŠ¶æ€
            inputs = {
                "user_input": user_input,      # ç”¨æˆ·è¾“å…¥
                "processed_result": "",        # å¤„ç†ç»“æœï¼ˆåˆå§‹ä¸ºç©ºï¼‰
                "steps": [],                   # æ‰§è¡Œæ­¥éª¤ï¼ˆåˆå§‹ä¸ºç©ºï¼‰
                "decision": "",                # å†³ç­–ç»“æœï¼ˆåˆå§‹ä¸ºç©ºï¼‰
            }
            result = interrupt_graph_app.invoke(inputs, config=cfg)

        # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿä¸­æ–­
        if isinstance(result, dict) and "__interrupt__" in result:
            # å·¥ä½œæµè¢«ä¸­æ–­ï¼Œéœ€è¦äººå·¥å¹²é¢„
            payload = result["__interrupt__"]  # ä¸­æ–­æ•°æ®
            yield _format_sse({
                "type": "interrupt",           # ç±»å‹ï¼šä¸­æ–­
                "node": "human_interaction",   # ä¸­æ–­èŠ‚ç‚¹ï¼šäººå·¥äº¤äº’
                "data": _safe_serialize(payload),  # ä¸­æ–­æ•°æ®ï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
                "thread_id": thread_id,        # ä¼šè¯ID
                "checkpoint": checkpoint       # æ£€æŸ¥ç‚¹ID
            }, event="interrupt")
            return  # ä¸­æ–­åç›´æ¥è¿”å›ï¼Œç­‰å¾…å®¢æˆ·ç«¯å‘é€æ¢å¤æ•°æ®

        # æå–æœ€ç»ˆç»“æœä¿¡æ¯
        steps = result.get("steps") if isinstance(result, dict) else None           # æ‰§è¡Œæ­¥éª¤
        processed = result.get("processed_result") if isinstance(result, dict) else None  # å¤„ç†ç»“æœ
        decision = result.get("decision") if isinstance(result, dict) else None     # å†³ç­–ç»“æœ
        
        # è°ƒè¯•æ¨¡å¼ï¼šå‘é€æ‰§è¡Œåçš„çŠ¶æ€ä¿¡æ¯
        yield _format_sse({
            "phase": "after_invoke",           # é˜¶æ®µï¼šæ‰§è¡Œå
            "steps": steps,                    # æ‰§è¡Œæ­¥éª¤
            "decision": decision,              # å†³ç­–ç»“æœ
            "has_tools_log": bool(isinstance(result, dict) and result.get("tools_log")),  # æ˜¯å¦æœ‰å·¥å…·æ—¥å¿—
            "node": result.get("current_node") if isinstance(result, dict) else None,     # å½“å‰èŠ‚ç‚¹
            "thread_id": thread_id,            # ä¼šè¯ID
            "checkpoint": checkpoint           # æ£€æŸ¥ç‚¹ID
        }, event="debug")
        
        # è¾“å‡ºå·¥å…·è°ƒç”¨æ˜ç»†ï¼šé€æ¡è¾“å‡ºæ¯ä¸ªå·¥å…·çš„è°ƒç”¨ç»“æœ
        if isinstance(result, dict):
            tools_log = result.get("tools_log")
            if isinstance(tools_log, list):
                for t in tools_log:
                    yield _format_sse({
                        "type": "tool",                    # ç±»å‹ï¼šå·¥å…·è°ƒç”¨
                        "node": result.get("current_node"), # è°ƒç”¨å·¥å…·æ‰€åœ¨çš„èŠ‚ç‚¹
                        "tool": t.get("tool"),             # å·¥å…·åç§°
                        "duration_ms": t.get("duration_ms"), # æ‰§è¡Œæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
                        "status": t.get("status"),         # æ‰§è¡ŒçŠ¶æ€
                        "data": _safe_serialize(t.get("output")),  # å·¥å…·è¾“å‡ºæ•°æ®
                        "thread_id": thread_id,            # ä¼šè¯ID
                        "checkpoint": checkpoint,          # æ£€æŸ¥ç‚¹ID
                    }, event="tool")
        
        # å‘é€æœ€ç»ˆå¤„ç†ç»“æœ
        yield _format_sse({
            "status": "ok",                    # çŠ¶æ€ï¼šæˆåŠŸ
            "steps": steps,                    # æ‰§è¡Œæ­¥éª¤
            "processed_result": processed,     # å¤„ç†ç»“æœ
            "decision": decision,              # å†³ç­–ç»“æœ
            "node": result.get("current_node") if isinstance(result, dict) else None,  # å½“å‰èŠ‚ç‚¹
            "thread_id": thread_id,            # ä¼šè¯ID
            "checkpoint": checkpoint,          # æ£€æŸ¥ç‚¹ID
        }, event="result")
        
        # å‘é€æµç¨‹ç»“æŸäº‹ä»¶
        yield _format_sse({"status": "completed", "thread_id": thread_id, "checkpoint": checkpoint}, event="end")
        
    except Exception as e:
        # å‘ç”Ÿé”™è¯¯ï¼Œå‘é€é”™è¯¯ä¿¡æ¯
        yield _format_sse({"status": "error", "message": str(e)}, event="error")
    finally:
        # ç¡®ä¿å‘é€æ¨¡å¼ç»“æŸäº‹ä»¶
        try:
            yield _format_sse({
                "mode": stream_mode or "updates",  # å½“å‰æµå¼æ¨¡å¼
                "status": "completed",             # çŠ¶æ€ï¼šå®Œæˆ
                "thread_id": thread_id,            # ä¼šè¯ID
                "checkpoint": checkpoint,          # æ£€æŸ¥ç‚¹ID
            }, event="mode_end")
        except Exception:
            # å‘é€æ¨¡å¼ç»“æŸäº‹ä»¶å¤±è´¥ï¼Œå¿½ç•¥
            pass


# å·²ç§»é™¤ HTTP æ¥å£ï¼Œä»…ä¿ç•™ WebSocket ç«¯ç‚¹

# ===== æ–°å¢ï¼šWebSocket ç«¯ç‚¹ =====
@app.websocket("/ws")
async def websocket_stream(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            try:
                message_text = await websocket.receive_text()
            except WebSocketDisconnect:
                break
            except Exception:
                # æœªèƒ½è§£ææ¶ˆæ¯ï¼Œå‘é€é”™è¯¯å¹¶ç»§ç»­
                await websocket.send_text(_format_sse({"status": "error", "message": "invalid message"}, event="error"))
                continue
            try:
                body = json.loads(message_text) if message_text else {}
            except Exception:
                body = {}
            user_input = body.get("user_input") or ""
            stream_mode = body.get("stream_mode") or "updates"
            thread_id = body.get("thread_id")
            checkpoint = body.get("checkpoint")
            replay_history = bool(body.get("replay_history", False))
            if not user_input:
                await websocket.send_text(_format_sse({"status": "error", "message": "missing user_input"}, event="error"))
                continue
            # å°†ç”Ÿæˆçš„äº‹ä»¶é€šè¿‡ WebSocket é€æ¡å‘é€ï¼ˆæ–‡æœ¬å¸§ï¼‰
            for line in _node_sse_generator(
                user_input,
                stream_mode=stream_mode,
                thread_id=thread_id,
                checkpoint=checkpoint,
                replay_history=replay_history,
            ):
                await websocket.send_text(line)
    except WebSocketDisconnect:
        pass
    except Exception as e:
        try:
            await websocket.send_text(_format_sse({"status": "error", "message": str(e)}, event="error"))
        except Exception:
            pass
    finally:
        try:
            await websocket.close()
        except Exception:
            pass



# ===== æ”¯æŒä¸­æ–­åŠŸèƒ½çš„ WebSocket ç«¯ç‚¹ =====
@app.websocket("/ws_interrupt")
async def websocket_stream_interrupt(websocket: WebSocket):
    """
    æ”¯æŒä¸­æ–­åŠŸèƒ½çš„ WebSocket æµå¼æ¥å£
    
    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. æ”¯æŒå·¥ä½œæµä¸­æ–­å’Œäººå·¥å¹²é¢„
    2. æ”¯æŒæ–­ç‚¹ç»­ä¼ å’ŒçŠ¶æ€æ¢å¤
    3. æ”¯æŒå†å²è®°å½•å›æ”¾
    4. æ”¯æŒå¤šç§æµå¼æ¨¡å¼
    
    æ¶ˆæ¯æ ¼å¼ï¼š
    - åˆå§‹è¯·æ±‚ï¼š{"user_input": "ç”¨æˆ·è¾“å…¥", "thread_id": "ä¼šè¯ID", "checkpoint": "æ£€æŸ¥ç‚¹ID"}
    - æ¢å¤è¯·æ±‚ï¼š{"resume": "æ¢å¤æ•°æ®", "thread_id": "ä¼šè¯ID", "checkpoint": "æ£€æŸ¥ç‚¹ID"}
    
    è¿”å›äº‹ä»¶ç±»å‹ï¼š
    - history: å†å²è®°å½•å›æ”¾
    - mode_start/mode_end: æ¨¡å¼å¼€å§‹/ç»“æŸ
    - interrupt: å·¥ä½œæµä¸­æ–­ï¼Œç­‰å¾…äººå·¥å¹²é¢„
    - debug: è°ƒè¯•ä¿¡æ¯
    - tool: å·¥å…·è°ƒç”¨ç»“æœ
    - result: æœ€ç»ˆå¤„ç†ç»“æœ
    - error: é”™è¯¯ä¿¡æ¯
    - end: æµç¨‹ç»“æŸ
    """
    # æ¥å— WebSocket è¿æ¥
    await websocket.accept()
    
    try:
        # æŒç»­ç›‘å¬å®¢æˆ·ç«¯æ¶ˆæ¯
        while True:
            try:
                # æ¥æ”¶å®¢æˆ·ç«¯å‘é€çš„æ–‡æœ¬æ¶ˆæ¯
                message_text = await websocket.receive_text()
            except WebSocketDisconnect:
                # å®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€è¿æ¥ï¼Œé€€å‡ºå¾ªç¯
                break
            except Exception:
                # æ¶ˆæ¯æ¥æ”¶å¤±è´¥ï¼Œå‘é€é”™è¯¯ä¿¡æ¯å¹¶ç»§ç»­ç›‘å¬
                await websocket.send_text(_format_sse({"status": "error", "message": "invalid message"}, event="error"))
                continue
            
            try:
                # è§£æ JSON æ ¼å¼çš„æ¶ˆæ¯ä½“
                body = json.loads(message_text) if message_text else {}
            except Exception:
                # JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—å…¸ä½œä¸ºé»˜è®¤å€¼
                body = {}
            
            # æå–è¯·æ±‚å‚æ•°
            user_input = body.get("user_input") or ""           # ç”¨æˆ·è¾“å…¥å†…å®¹
            stream_mode = body.get("stream_mode") or "updates"  # æµå¼æ¨¡å¼ï¼ˆé»˜è®¤updatesï¼‰
            thread_id = body.get("thread_id")                   # ä¼šè¯IDï¼Œç”¨äºçŠ¶æ€æŒä¹…åŒ–
            checkpoint = body.get("checkpoint")                 # æ£€æŸ¥ç‚¹IDï¼Œç”¨äºæ–­ç‚¹ç»­ä¼ 
            replay_history = bool(body.get("replay_history", False))  # æ˜¯å¦å›æ”¾å†å²è®°å½•
            resume = body.get("resume")                         # æ¢å¤æ•°æ®ï¼Œç”¨äºä»ä¸­æ–­ç‚¹ç»§ç»­æ‰§è¡Œ
            
            # å‚æ•°éªŒè¯ï¼šå¿…é¡»æä¾›ç”¨æˆ·è¾“å…¥æˆ–æ¢å¤æ•°æ®
            if not user_input and not resume:
                await websocket.send_text(_format_sse({"status": "error", "message": "missing user_input or resume"}, event="error"))
                continue
            
            # è°ƒç”¨ä¸­æ–­å·¥ä½œæµç”Ÿæˆå™¨ï¼Œé€æ¡å‘é€æµå¼äº‹ä»¶
            for line in _node_sse_generator_interrupt(
                user_input,                    # ç”¨æˆ·è¾“å…¥
                stream_mode=stream_mode,       # æµå¼æ¨¡å¼
                thread_id=thread_id,           # ä¼šè¯ID
                checkpoint=checkpoint,         # æ£€æŸ¥ç‚¹ID
                replay_history=replay_history, # å†å²å›æ”¾
                resume=resume,                 # æ¢å¤æ•°æ®
            ):
                # å°†æ¯ä¸ªäº‹ä»¶é€šè¿‡ WebSocket å‘é€ç»™å®¢æˆ·ç«¯
                await websocket.send_text(line)
                
    except WebSocketDisconnect:
        # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
        pass
    except Exception as e:
        # å‘ç”Ÿæœªé¢„æœŸé”™è¯¯ï¼Œå°è¯•å‘é€é”™è¯¯ä¿¡æ¯ç»™å®¢æˆ·ç«¯
        try:
            await websocket.send_text(_format_sse({"status": "error", "message": str(e)}, event="error"))
        except Exception:
            # å‘é€é”™è¯¯ä¿¡æ¯ä¹Ÿå¤±è´¥ï¼Œå¿½ç•¥
            pass
    finally:
        # ç¡®ä¿ WebSocket è¿æ¥è¢«æ­£ç¡®å…³é—­
        try:
            await websocket.close()
        except Exception:
            # å…³é—­è¿æ¥å¤±è´¥ï¼Œå¿½ç•¥
            pass




if __name__ == "__main__":
    # é»˜è®¤å¯åŠ¨ FastAPI æœåŠ¡ï¼ˆä½¿ç”¨å¯¼å…¥å­—ç¬¦ä¸²ä»¥å¯ç”¨ reload/workersï¼‰
    # todo cd langgraph_demo/study 
    import uvicorn
    uvicorn.run("11_stream_fastapi_ws_interrupt:app", host="0.0.0.0", port=8000, reload=False)
    
    print("\nâœ… èŠ‚ç‚¹åç§°è‡ªå®šä¹‰ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“š å­¦ä¹ è¦ç‚¹æ€»ç»“:")
    print("1. èŠ‚ç‚¹åç§°é…ç½®: æ”¯æŒä¸­æ–‡ã€emojiå’Œæè¿°")
    print("2. çŠ¶æ€è·Ÿè¸ª: å®æ—¶ç›‘æ§å½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹")
    print("3. æ˜¾ç¤ºåç§°: ç”¨æˆ·å‹å¥½çš„èŠ‚ç‚¹å±•ç¤º")
    print("4. é…ç½®ç®¡ç†: ç»Ÿä¸€çš„èŠ‚ç‚¹é…ç½®å­—å…¸")
    print("5. åŠ¨æ€è·å–: æ ¹æ®èŠ‚ç‚¹åè·å–é…ç½®ä¿¡æ¯")
    print("6. æ‰§è¡Œæ—¥å¿—: è¯¦ç»†çš„èŠ‚ç‚¹æ‰§è¡Œè®°å½•") 